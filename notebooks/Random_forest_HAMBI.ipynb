{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d05cf26d-9f98-4db4-96dc-009cfe247c32",
   "metadata": {},
   "source": [
    "# Random Forest for HAMBI data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f9ed8-c1e1-4d87-820b-748006821753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "seed = 98\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf71140-d23d-4138-b904-9b662322bff2",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20258d0a-96ec-47ec-ae4d-2c9ab76989a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '/scratch/project_2006608/Methylation/notebooks/RF_HAMBI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5015f7d-dc2c-44ec-98ef-9cbb2952f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/scratch/project_2006608/Methylation/HAMBI_data/merged_data.tsv\", sep=\"\\t\", index_col=0, header=0,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dfcb54-f39d-410f-b8dd-995d7435d237",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794fba1a-32fd-491f-a6b7-63ff2d91696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Domain to species'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca63a6e-c0b6-4ba6-ac02-acaa639b841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['Domain to species'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d75ffd-b0c0-4910-b587-4778d5598b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd1b13-c6d7-4c3c-bc73-7a104f2a3d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['Domain to species'].value_counts(dropna=False))\n",
    "len(data['s'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de7f38-634e-4a51-8315-d6bfce567622",
   "metadata": {},
   "source": [
    "## Random forest classifier \n",
    "### All data ðŸ’ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ebec8e-0b18-437b-be6a-538d86138728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    classes_before = set(data['s'].unique())\n",
    "    print(f\"before filtering number of classes {len(data['s'].value_counts())}\")   \n",
    "    data_filtered = data.dropna(subset=['All'], axis=0)\n",
    "    data_filtered = data_filtered[(data_filtered['All'] != '') & (data_filtered['All'] != 'Bacteria')]\n",
    "    data_filtered = data_filtered[(data_filtered.iloc[:, :492] != 0).any(axis=1)]\n",
    "    print(f\"after filtering number of classes {len(data_filtered['s'].value_counts())}\")\n",
    "    classes_after = set(data_filtered['s'].unique())\n",
    "    dropped_classes = classes_before - classes_after\n",
    "    if dropped_classes:\n",
    "        print(f\"Dropped classes: {dropped_classes}\")\n",
    "    else:\n",
    "        print(\"No classes were dropped.\")\n",
    "    return data_filtered\n",
    "\n",
    "def filter_out_n(data: pd.DataFrame, column_name: str, n: int) -> pd.DataFrame:\n",
    "    \"\"\"Filter out the contigs that have less than n samples in the given column.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): Data frame with the data.\n",
    "    - column_name (str): Column name to filter out.\n",
    "    - n (int): Minimum number of samples.\n",
    "    \"\"\"\n",
    "    print(f\"before filtering number of classes {len(data[column_name].value_counts())}\")\n",
    "    counts = data[column_name].value_counts()\n",
    "    classes = counts[counts > n].index\n",
    "    filtered_data = data[data[column_name].isin(classes)]\n",
    "    filtered_data = filtered_data.dropna(subset=[column_name], axis=0)\n",
    "    print(f\"after filtering number of classes {len(filtered_data[column_name].value_counts())}\")\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "def plot_confusion_matrix(y_true: pd.Series, y_pred: pd.Series, model: RandomForestClassifier, title: str, output_dir: str, target: str):\n",
    "    \"\"\"Plot the confusion matrix for the given true and predicted values.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true (pd.Series): True labels.\n",
    "    - y_pred (pd.Series): Predicted labels.\n",
    "    - model (RandomForestClassifier): Trained model.\n",
    "    - title (str): Title of the plot.\n",
    "    - output_dir (str): Path to the output directory where the plot will be saved.\n",
    "    - target (str): Target colu<mn.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(50, 50))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu', xticklabels=model.classes_, yticklabels=model.classes_, cbar=True,\n",
    "                annot_kws={\"size\": 50})\n",
    "    plt.xticks(rotation=90, fontsize=40, fontstyle='italic'\n",
    "               #horizontalalignment='left', verticalalignment='baseline'\n",
    "              )\n",
    "    plt.yticks(rotation=0, fontsize=40, fontstyle='italic')\n",
    "    plt.title(f'{title} - Accuracy: {accuracy_score(y_true, y_pred):.2f}', fontsize=80)\n",
    "    plt.xlabel('Predicted Labels', fontsize=50)\n",
    "    plt.ylabel('True Labels', fontsize=50)\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    title = title.replace(' ', '_')\n",
    "    plt.savefig(os.path.join(output_dir, f'{title}.png'))\n",
    "    plt.savefig(os.path.join(output_dir, f'{title}.jpg'))\n",
    "\n",
    "    # Edit when you have chosen the number of features\n",
    "    plt.savefig(os.path.join(output_folder, f'{target}_confusion_mat.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "def plot_train_test_distribution(y_train: pd.Series, y_test: pd.Series, output_dir: str, target: str):\n",
    "    \"\"\"Plot the distribution of the train and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_train (pd.Series): True labels of the train set.\n",
    "    - y_test (pd.Series): True labels of the test set.\n",
    "    - output_dir (str): Path to the output directory.\n",
    "    \"\"\"\n",
    "    print(\"Plotting the distribution\")\n",
    "    train_species_counts = y_train.value_counts()\n",
    "    test_species_counts = y_test.value_counts()\n",
    "    \n",
    "    print(\"Number of samples in each species in the train set:\")\n",
    "    print(train_species_counts)\n",
    "    print(\"\\nNumber of samples in each species in the test set:\")\n",
    "    print(test_species_counts)\n",
    "    num_classes = len(set(y_train.unique()).union(set(y_test.unique())))\n",
    "    \n",
    "    width = max(12, num_classes * 0.6)\n",
    "    height = max(8, num_classes * 0.8)\n",
    "    \n",
    "    plt.figure(figsize=(width, height))\n",
    "    \n",
    "    categories = pd.concat([y_train, y_test]).value_counts().index\n",
    "    train_counts = y_train.value_counts().reindex(categories, fill_value=0)\n",
    "    test_counts = y_test.value_counts().reindex(categories, fill_value=0)\n",
    "    \n",
    "    indices = range(len(categories))\n",
    "    bar_width = 0.4 \n",
    "\n",
    "    plt.bar([i - bar_width / 2 for i in indices], train_counts, width=bar_width, color='blue', alpha=0.5, label='Train')\n",
    "    plt.bar([i + bar_width / 2 for i in indices], test_counts, width=bar_width, color='red', alpha=0.5, label='Test')\n",
    "    \n",
    "    plt.xticks(indices, categories, rotation=90, fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "    target = target.replace(' ', '_')\n",
    "    plt.savefig(os.path.join(output_dir, f'{target}_train_test_distribution.png'), bbox_inches='tight')\n",
    "\n",
    "    plt.savefig(os.path.join(output_dir, f'{target}_train_test_distribution.jpg'))\n",
    "    plt.show()\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(model: RandomForestClassifier, X: pd.DataFrame, target:str, top_n: int = 30, output_dir: str = None):\n",
    "    \"\"\"Plot the feature importance of the model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model (RandomForestClassifier): Trained model.\n",
    "    - X (pd.DataFrame): Data frame with the features.\n",
    "    - target (str): Target column.\n",
    "    - top_n (int): Number of top features to plot.\n",
    "    - output_dir (str): Path to the output directory.\n",
    "    \"\"\"\n",
    "\n",
    "# ***\n",
    "    methylation_colors = {\n",
    "        'm6A': 'skyblue',\n",
    "        'm4C': 'lightcoral',\n",
    "        'modified_base': 'lightgreen',\n",
    "        'other': 'gray'\n",
    "    }\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    top_indices = indices[:top_n]\n",
    "    top_features = X.columns[top_indices]\n",
    "\n",
    "    def get_color(feature_name):\n",
    "        if 'm6A' in feature_name:\n",
    "            return methylation_colors['m6A']\n",
    "        elif 'm4C' in feature_name:\n",
    "            return methylation_colors['m4C']\n",
    "        elif 'modified_base' in feature_name:\n",
    "            return methylation_colors['modified_base']\n",
    "        else:\n",
    "            return methylation_colors['other']\n",
    "\n",
    "    bar_colors = [get_color(feature) for feature in top_features]\n",
    "# ***\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.bar(range(top_n), importances[top_indices], align='center', color=bar_colors)\n",
    "    plt.xticks(range(top_n), X.columns[top_indices], rotation=45, ha='right', fontsize=10)\n",
    "    plt.title(f\"Feature Importance of {top_n} features with target {target}\", fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    output_name = f'{target.replace(\" \", \"_\")}_feature_importance_colors.png'\n",
    "#    output_name = f'{target.replace(\" \", \"_\")}_feature_importance.png'\n",
    "    plt.savefig(os.path.join(output_dir, output_name))\n",
    "    plt.savefig(os.path.join(output_dir, output_name.replace('.png', '.jpg')))\n",
    "    plt.close()\n",
    "\n",
    "def train_test_model(df: pd.DataFrame, output_folder: str, target: str):\n",
    "    \"\"\"Train and test the random forest classifier.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Data frame with the data.\n",
    "    - output_folder (str): Path to the output directory to save the results for the model plots\n",
    "    - target (str): Target column.\n",
    "    \"\"\"\n",
    "    print(f\"Training the model with target: {target}\")\n",
    "    filtered_data = clean_data(df)\n",
    "    filtered_data = filter_out_n(filtered_data, target, 10)\n",
    "    \n",
    "    X_DS = filtered_data.iloc[:, :492] \n",
    "    y_DS = filtered_data[target]\n",
    "\n",
    "    X_train_DS, X_test_DS, y_train_DS, y_test_DS = train_test_split(X_DS, y_DS, test_size=0.2, random_state=seed, stratify=y_DS)\n",
    "    plot_train_test_distribution(y_train_DS, y_test_DS, output_folder, target)\n",
    "    model = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "    model.fit(X_train_DS, y_train_DS)\n",
    "\n",
    "    y_train_pred_DS = model.predict(X_train_DS)\n",
    "    y_test_pred_DS = model.predict(X_test_DS)\n",
    "\n",
    "    plot_confusion_matrix(y_train_DS, y_train_pred_DS, model, f'Train Set with target {target}', output_folder, target)\n",
    "    plot_confusion_matrix(y_test_DS, y_test_pred_DS, model, f'Test Set with target {target}', output_folder, target)\n",
    "\n",
    "    plot_feature_importance(model, X_DS, target, 30, output_folder)\n",
    "\n",
    "    metrics = pd.DataFrame({\n",
    "            'Accuracy Train': [accuracy_score(y_train_DS, y_train_pred_DS)],\n",
    "            'Accuracy Test': [accuracy_score(y_test_DS, y_test_pred_DS)],\n",
    "            'Precision': [precision_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)],\n",
    "            'Recall': [recall_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)],\n",
    "            'F1 Score': [f1_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)]\n",
    "        })\n",
    "    \n",
    "    metrics.to_csv(os.path.join(output_folder, f'{target.replace(\" \", \"_\")}_metrics.tsv'), sep='\\t')\n",
    "    print(f\"Metrics for target {target}\")\n",
    "    print(metrics)\n",
    "\n",
    "    if accuracy_score(y_test_DS, y_test_pred_DS) > 0.7:\n",
    "        print(f\"Model trained with accuracy: {accuracy_score(y_test_DS, y_test_pred_DS)}\")\n",
    "        model_file_path = os.path.join(output_folder, f'{target.replace(\" \", \"_\")}_model.joblib')\n",
    "        print(f\"Saving the model to {model_file_path}\")\n",
    "        joblib.dump(model, model_file_path)\n",
    "    else:\n",
    "        print(f\"Model trained with accuracy: {accuracy_score(y_test_DS, y_test_pred_DS)}\")\n",
    "    return y_test_DS, y_test_pred_DS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5985eb5f-d31a-44e9-8d1b-08c80ba7f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '/scratch/project_2006608/Methylation/notebooks/RF_HAMBI'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "y_test_DS, y_test_pred_DS = train_test_model(data, output_folder, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6423d492-04a6-4fdf-b107-2dbdabd5d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(y_test_pred_DS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ddb780-93ce-450e-af50-cb7346d956d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data, output_folder, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb2690b-62be-410c-ba1b-ce5b809fefb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data, output_folder, 'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0adfb9-1494-4a6f-9241-1ca846694f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data, output_folder, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b895c8-d143-48fb-8a68-15f53f0609f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data, output_folder, 'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08fe41f-fa7b-4bdd-860a-c8b099c357f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data, output_folder, 'p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db01a5a-b1c6-415e-a0cf-c07747bb3158",
   "metadata": {},
   "source": [
    "## Trying different number of features \n",
    "### All data ðŸ’ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b8869-1f91-4086-a3cb-a26c83e62b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    classes_before = set(data['Domain to species'].unique())\n",
    "    print(f\"Before filtering, number of classes: {len(data['Domain to species'].value_counts())}\")    \n",
    "    data_filtered = data.dropna(subset=['All'], axis=0)\n",
    "    data_filtered = data_filtered[(data_filtered['All'] != '') & (data_filtered['All'] != 'Bacteria')]\n",
    "    data_filtered = data_filtered[(data_filtered.iloc[:, :492] != 0).any(axis=1)]\n",
    "    print(f\"After filtering, number of classes: {len(data_filtered['Domain to species'].value_counts())}\")\n",
    "    classes_after = set(data_filtered['Domain to species'].unique())\n",
    "    dropped_classes = classes_before - classes_after\n",
    "    if dropped_classes:\n",
    "        print(f\"Dropped classes: {dropped_classes}\")\n",
    "    else:\n",
    "        print(\"No classes were dropped.\")\n",
    "    return data_filtered\n",
    "\n",
    "def filter_out_n(data: pd.DataFrame, column_name: str, n: int) -> pd.DataFrame:\n",
    "    print(f\"Before filtering, number of classes: {len(data[column_name].value_counts())}\")\n",
    "    counts = data[column_name].value_counts()\n",
    "    classes = counts[counts > n].index\n",
    "    filtered_data = data[data[column_name].isin(classes)]\n",
    "    filtered_data = filtered_data.dropna(subset=[column_name], axis=0)\n",
    "    print(f\"After filtering, number of classes: {len(filtered_data[column_name].value_counts())}\")\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "def plot_confusion_matrix(y_true: pd.Series, y_pred: pd.Series, model, title: str, target: str):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu', xticklabels=model.classes_, yticklabels=model.classes_, cbar=True)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.title(f'{title} - Accuracy: {accuracy_score(y_true, y_pred):.2f}')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Edit when you have chosen the number of features\n",
    "    plt.savefig(os.path.join(output_folder, f'{target}_confusion_mat_150.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_train_test_distribution(y_train: pd.Series, y_test: pd.Series, target: str):\n",
    "    print(\"Plotting the distribution of train and test sets\")\n",
    "    train_species_counts = y_train.value_counts()\n",
    "    test_species_counts = y_test.value_counts()\n",
    "    \n",
    "    categories = pd.concat([y_train, y_test]).value_counts().index\n",
    "    train_counts = y_train.value_counts().reindex(categories, fill_value=0)\n",
    "    test_counts = y_test.value_counts().reindex(categories, fill_value=0)\n",
    "    \n",
    "    indices = range(len(categories))\n",
    "    bar_width = 0.4 \n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar([i - bar_width / 2 for i in indices], train_counts, width=bar_width, color='blue', alpha=0.5, label='Train')\n",
    "    plt.bar([i + bar_width / 2 for i in indices], test_counts, width=bar_width, color='red', alpha=0.5, label='Test')\n",
    "    \n",
    "    plt.xticks(indices, categories, rotation=90)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_feature_importance(model: RandomForestClassifier, X: pd.DataFrame, target: str, top_n: int = 30):\n",
    "    \"\"\"Plot the feature importance of the model with color-coded bars by methylation type.\n",
    "    \n",
    "    Parameters:\n",
    "    - model (RandomForestClassifier): Trained model.\n",
    "    - X (pd.DataFrame): Data frame with the features.\n",
    "    - target (str): Target column.\n",
    "    - top_n (int): Number of top features to plot.\n",
    "    \"\"\"\n",
    "    methylation_colors = {\n",
    "        'm6A': 'skyblue',\n",
    "        'm4C': 'lightcoral',\n",
    "        'modified_base': 'lightgreen',\n",
    "        'other': 'gray'\n",
    "    }\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    top_indices = indices[:top_n]\n",
    "    top_features = X.columns[top_indices]\n",
    "\n",
    "    def get_color(feature_name):\n",
    "        if 'm6A' in feature_name:\n",
    "            return methylation_colors['m6A']\n",
    "        elif 'm4C' in feature_name:\n",
    "            return methylation_colors['m4C']\n",
    "        elif 'modified_base' in feature_name:\n",
    "            return methylation_colors['modified_base']\n",
    "        else:\n",
    "            return methylation_colors['other']\n",
    "\n",
    "    bar_colors = [get_color(feature) for feature in top_features]\n",
    "\n",
    "    # Vertical bar plot\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.bar(range(top_n), importances[top_indices], align='center', color=bar_colors)\n",
    "    plt.xticks(range(top_n), top_features, rotation=45, ha='right', fontsize=10)\n",
    "    plt.title(f\"Feature Importance of Top {top_n} Features with Target {target}\", fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Horizontal bar plot\n",
    "    fig, ax = plt.subplots(figsize=(20, max(5, top_n // 3)))\n",
    "    ax.barh(range(top_n), importances[top_indices], color=bar_colors)\n",
    "    ax.set_yticks(range(top_n))\n",
    "    ax.set_yticklabels(top_features, fontsize=8)\n",
    "    ax.set_ylim(-0.5, top_n - 0.5) \n",
    "\n",
    "    ax.set_xlim(0, max(importances[top_indices]) * 1.05)\n",
    "\n",
    "    plt.title(f\"Feature Importance of Top {top_n} Features with Target {target}\", fontsize=20)\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.save\n",
    "    plt.savefig(os.path.join(output_folder, f'{target}_features.png'))\n",
    "    plt.show()\n",
    "\n",
    "def train_test_model(df: pd.DataFrame, target: str, n:int):\n",
    "    \n",
    "    print(f\"Training the model with target: {target}\")\n",
    "    filtered_data = clean_data(df)\n",
    "    filtered_data = filter_out_n(filtered_data, target, 10)\n",
    "    \n",
    "    X = filtered_data.iloc[:, :492]\n",
    "    y = filtered_data[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)\n",
    "    plot_train_test_distribution(y_train, y_test, target)\n",
    "\n",
    "    model = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    #plot_confusion_matrix(y_train, y_train_pred, model, 'Train Set', target)\n",
    "    #plot_confusion_matrix(y_test, y_test_pred, model, 'Test Set', target)\n",
    "\n",
    "    plot_feature_importance(model, X, target, top_n=n)\n",
    "\n",
    "    metrics = pd.DataFrame({\n",
    "        'Accuracy Train': [accuracy_score(y_train, y_train_pred)],\n",
    "        'Accuracy Test': [accuracy_score(y_test, y_test_pred)],\n",
    "        'Precision': [precision_score(y_test, y_test_pred, average='weighted', zero_division=0)],\n",
    "        'Recall': [recall_score(y_test, y_test_pred, average='weighted', zero_division=0)],\n",
    "        'F1 Score': [f1_score(y_test, y_test_pred, average='weighted', zero_division=0)]\n",
    "    })\n",
    "    print(f\"Metrics for target {target} with all features\")\n",
    "    print(metrics)\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    top_n = n\n",
    "    top_features_indices = np.argsort(importances)[::-1][:top_n]\n",
    "    X_train_top = X_train.iloc[:, top_features_indices]\n",
    "    X_test_top = X_test.iloc[:, top_features_indices]\n",
    "\n",
    "    model_top = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "    model_top.fit(X_train_top, y_train)\n",
    "\n",
    "    y_train_pred = model_top.predict(X_train_top)\n",
    "    y_test_pred = model_top.predict(X_test_top)\n",
    "\n",
    "    plot_confusion_matrix(y_train, y_train_pred, model_top, 'Train Set', target)\n",
    "    plot_confusion_matrix(y_test, y_test_pred, model_top, 'Test Set', target)\n",
    "\n",
    "\n",
    "    metrics = pd.DataFrame({\n",
    "        'Accuracy Train': [accuracy_score(y_train, y_train_pred)],\n",
    "        'Accuracy Test': [accuracy_score(y_test, y_test_pred)],\n",
    "        'Precision': [precision_score(y_test, y_test_pred, average='weighted', zero_division=0)],\n",
    "        'Recall': [recall_score(y_test, y_test_pred, average='weighted', zero_division=0)],\n",
    "        'F1 Score': [f1_score(y_test, y_test_pred, average='weighted', zero_division=0)]\n",
    "    })\n",
    "    print(f\"Metrics for target {target} with top {n} features\")\n",
    "    print(metrics)\n",
    "\n",
    "    return y_test, y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f81f6ad-0f4c-4dcb-b3a6-b3c0243a1d4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8f6111-6ae7-4ed8-a142-af05aac30763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d9c36-2a59-4eab-ab55-3ef5291b2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a115a1d-85d2-487c-b8ba-b1c1447233a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a30f0c3-8c7b-47e1-935a-63f1cc0e3608",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c532a7-d931-42fd-8c79-0586ef843f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31fbded-e086-48d6-877e-655979a130c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddad22e-0be4-4f8f-83bc-33e371df4582",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23673375-172d-4a0f-abce-5f741f25bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c5134-6082-47b7-af9e-2a0be12a6378",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7346a-7017-4bc6-b7d1-ce65c30af23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618395d6-21b3-43f9-a566-22d225b6de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be1922f-96dc-4498-8d41-411e84796304",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e444e54-9f0d-4ad0-aba2-bf964e540389",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4babd-3775-44bf-93a0-96a12037c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af19307e-5b76-4828-b090-e333f192dbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4aeb0a-0525-4e9c-831c-0679240a86b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "*******************************************\n",
    "## Create data without element 'plasmid'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb34eab-f5c6-4240-af3e-fd1f05693500",
   "metadata": {},
   "source": [
    "## Random forest classifier \n",
    "### Chromosome data ðŸ”²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007dd02e-1ccb-4f38-8081-a1081b876821",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_data = data[data['element'].str.contains('chromo', case=False, na=True)]\n",
    "chrom_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d65f6e0-fa27-4c87-a75e-06fae60d9b07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "has_nan = chrom_data['All'].isna().any()\n",
    "print(has_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f262b62e-1df6-45b2-a29a-d6b86807d939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chrom_data['Domain to species'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5301c-348e-4465-ad6f-125cc0e922d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chrom_data['Domain to species'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c27b9b-17ea-4ea4-8f63-fe21868c9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chrom_data.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da71298-9e5c-4825-bb57-cce844d21fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    classes_before = set(chrom_data['s'].unique())\n",
    "    print(f\"before filtering number of classes {len(chrom_data['s'].value_counts())}\")    \n",
    "    chrom_data_filtered = chrom_data.dropna(subset=['All'], axis=0)\n",
    "    chrom_data_filtered = chrom_data_filtered[(chrom_data_filtered['All'] != '') & (chrom_data_filtered['All'] != 'Bacteria')]\n",
    "    chrom_data_filtered = chrom_data_filtered[(chrom_data_filtered.iloc[:, :492] != 0).any(axis=1)]\n",
    "    print(f\"after filtering number of classes {len(chrom_data_filtered['s'].value_counts())}\")\n",
    "    classes_after = set(chrom_data_filtered['s'].unique())\n",
    "    dropped_classes = classes_before - classes_after\n",
    "    if dropped_classes:\n",
    "        print(f\"Dropped classes: {dropped_classes}\")\n",
    "    else:\n",
    "        print(\"No classes were dropped.\")\n",
    "    return chrom_data_filtered\n",
    "\n",
    "def filter_out_n(data: pd.DataFrame, column_name: str, n: int) -> pd.DataFrame:\n",
    "    \"\"\"Filter out the contigs that have less than n samples in the given column.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): Data frame with the data.\n",
    "    - column_name (str): Column name to filter out.\n",
    "    - n (int): Minimum number of samples.\n",
    "    \"\"\"\n",
    "    print(f\"before filtering number of classes {len(chrom_data[column_name].value_counts())}\")\n",
    "    counts = chrom_data[column_name].value_counts()\n",
    "    classes = counts[counts > n].index\n",
    "    filtered_chrom_data = chrom_data[chrom_data[column_name].isin(classes)]\n",
    "    filtered_chrom_data = filtered_chrom_data.dropna(subset=[column_name], axis=0)\n",
    "    print(f\"after filtering number of classes {len(filtered_chrom_data[column_name].value_counts())}\")\n",
    "\n",
    "    return filtered_chrom_data\n",
    "\n",
    "def plot_confusion_matrix(y_true: pd.Series, y_pred: pd.Series, model: RandomForestClassifier, title: str, output_dir: str, target: str):\n",
    "    \"\"\"Plot the confusion matrix for the given true and predicted values.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true (pd.Series): True labels.\n",
    "    - y_pred (pd.Series): Predicted labels.\n",
    "    - model (RandomForestClassifier): Trained model.\n",
    "    - title (str): Title of the plot.\n",
    "    - output_dir (str): Path to the output directory where the plot will be saved.\n",
    "    - target (str): Target column.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(50, 50))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu', xticklabels=model.classes_, yticklabels=model.classes_, cbar=True,\n",
    "                annot_kws={\"size\": 50})\n",
    "    plt.xticks(rotation=90, fontsize=40, fontstyle='italic'\n",
    "               #horizontalalignment='left', verticalalignment='baseline'\n",
    "              )\n",
    "    plt.yticks(rotation=0, fontsize=40, fontstyle='italic')\n",
    "    plt.title(f'{title} - Accuracy: {accuracy_score(y_true, y_pred):.2f}', fontsize=80)\n",
    "    plt.xlabel('Predicted Labels', fontsize=50)\n",
    "    plt.ylabel('True Labels', fontsize=50)\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    title = title.replace(' ', '_')\n",
    "    plt.savefig(os.path.join(output_dir, f'{title}.png'))\n",
    "    plt.savefig(os.path.join(output_dir, f'{title}.jpg'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_train_test_distribution(y_train: pd.Series, y_test: pd.Series, output_dir: str, target: str):\n",
    "    \"\"\"Plot the distribution of the train and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_train (pd.Series): True labels of the train set.\n",
    "    - y_test (pd.Series): True labels of the test set.\n",
    "    - output_dir (str): Path to the output directory.\n",
    "    \"\"\"\n",
    "    print(\"Plotting the distribution\")\n",
    "    train_species_counts = y_train.value_counts()\n",
    "    test_species_counts = y_test.value_counts()\n",
    "    \n",
    "    print(\"Number of samples in each species in the train set:\")\n",
    "    print(train_species_counts)\n",
    "    print(\"\\nNumber of samples in each species in the test set:\")\n",
    "    print(test_species_counts)\n",
    "    num_classes = len(set(y_train.unique()).union(set(y_test.unique())))\n",
    "    \n",
    "    width = max(12, num_classes * 0.6)\n",
    "    height = max(8, num_classes * 0.8)\n",
    "    \n",
    "    plt.figure(figsize=(width, height))\n",
    "    \n",
    "    categories = pd.concat([y_train, y_test]).value_counts().index\n",
    "    train_counts = y_train.value_counts().reindex(categories, fill_value=0)\n",
    "    test_counts = y_test.value_counts().reindex(categories, fill_value=0)\n",
    "    \n",
    "    indices = range(len(categories))\n",
    "    bar_width = 0.4 \n",
    "\n",
    "    plt.bar([i - bar_width / 2 for i in indices], train_counts, width=bar_width, color='blue', alpha=0.5, label='Train')\n",
    "    plt.bar([i + bar_width / 2 for i in indices], test_counts, width=bar_width, color='red', alpha=0.5, label='Test')\n",
    "    \n",
    "    plt.xticks(indices, categories, rotation=90, fontsize=10)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "    target = target.replace(' ', '_')\n",
    "    plt.savefig(os.path.join(output_dir, f'{target}_train_test_distribution.png'), bbox_inches='tight')\n",
    "\n",
    "    plt.savefig(os.path.join(output_dir, f'{target}_train_test_distribution.jpg'))\n",
    "    plt.show()\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(model: RandomForestClassifier, X: pd.DataFrame, target:str, top_n: int = 30, output_dir: str = None):\n",
    "    \"\"\"Plot the feature importance of the model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model (RandomForestClassifier): Trained model.\n",
    "    - X (pd.DataFrame): Data frame with the features.\n",
    "    - target (str): Target column.\n",
    "    - top_n (int): Number of top features to plot.\n",
    "    - output_dir (str): Path to the output directory.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    top_indices = indices[:top_n]\n",
    "    plt.bar(range(top_n), importances[top_indices], align='center', color='skyblue')\n",
    "    plt.xticks(range(top_n), X.columns[top_indices], rotation=45, ha='right', fontsize=10)\n",
    "    plt.title(f\"Feature Importance of {top_n} features with target {target}\", fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    output_name = f'{target.replace(\" \", \"_\")}_feature_importance.png'\n",
    "    plt.savefig(os.path.join(output_dir, output_name))\n",
    "    plt.savefig(os.path.join(output_dir, output_name.replace('.png', '.jpg')))\n",
    "    plt.close()\n",
    "\n",
    "def train_test_model(df: pd.DataFrame, output_folder_chrom: str, target: str):\n",
    "    \"\"\"Train and test the random forest classifier.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Data frame with the data.\n",
    "    - output_folder_chrom (str): Path to the output directory to save the results for the model plots\n",
    "    - target (str): Target column.\n",
    "    \"\"\"\n",
    "    print(f\"Training the model with target: {target}\")\n",
    "    filtered_chrom_data = clean_data(df)\n",
    "    filtered_chrom_data = filter_out_n(filtered_chrom_data, target, 10)\n",
    "    \n",
    "    X_DS = filtered_chrom_data.iloc[:, :492] \n",
    "    y_DS = filtered_chrom_data[target]\n",
    "\n",
    "    X_train_DS, X_test_DS, y_train_DS, y_test_DS = train_test_split(X_DS, y_DS, test_size=0.2, random_state=seed, stratify=y_DS)\n",
    "    plot_train_test_distribution(y_train_DS, y_test_DS, output_folder_chrom, target)\n",
    "    model = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "    model.fit(X_train_DS, y_train_DS)\n",
    "\n",
    "    y_train_pred_DS = model.predict(X_train_DS)\n",
    "    y_test_pred_DS = model.predict(X_test_DS)\n",
    "\n",
    "    plot_confusion_matrix(y_train_DS, y_train_pred_DS, model, f'Train Set with target {target}', output_folder_chrom, target)\n",
    "    plot_confusion_matrix(y_test_DS, y_test_pred_DS, model, f'Test Set with target {target}', output_folder_chrom, target)\n",
    "\n",
    "    plot_feature_importance(model, X_DS, target, 30, output_folder_chrom)\n",
    "\n",
    "    metrics = pd.DataFrame({\n",
    "            'Accuracy Train': [accuracy_score(y_train_DS, y_train_pred_DS)],\n",
    "            'Accuracy Test': [accuracy_score(y_test_DS, y_test_pred_DS)],\n",
    "            'Precision': [precision_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)],\n",
    "            'Recall': [recall_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)],\n",
    "            'F1 Score': [f1_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)]\n",
    "        })\n",
    "    \n",
    "    metrics.to_csv(os.path.join(output_folder_chrom, f'{target.replace(\" \", \"_\")}_metrics.tsv'), sep='\\t')\n",
    "    print(f\"Metrics for target {target}\")\n",
    "    print(metrics)\n",
    "\n",
    "    if accuracy_score(y_test_DS, y_test_pred_DS) > 0.7:\n",
    "        print(f\"Model trained with accuracy: {accuracy_score(y_test_DS, y_test_pred_DS)}\")\n",
    "        model_file_path = os.path.join(output_folder_chrom, f'{target.replace(\" \", \"_\")}_model.joblib')\n",
    "        print(f\"Saving the model to {model_file_path}\")\n",
    "        joblib.dump(model, model_file_path)\n",
    "    else:\n",
    "        print(f\"Model trained with accuracy: {accuracy_score(y_test_DS, y_test_pred_DS)}\")\n",
    "    return y_test_DS, y_test_pred_DS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c31c7-fe74-45e7-8bfc-cd1259c68d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_chrom = '/scratch/project_2006608/Methylation/notebooks/RF_HAMBI_chrom'\n",
    "if not os.path.exists(output_folder_chrom):\n",
    "    os.makedirs(output_folder_chrom)\n",
    "\n",
    "y_test_DS, y_test_pred_DS = train_test_model(chrom_data, output_folder_chrom, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a89899-ddd1-4c92-ace5-bbc1d8c9d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(y_test_pred_DS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663e0173-df77-4e36-9557-61adab5eb703",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(chrom_data, output_folder_chrom, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf4f3e2-c11b-453c-85cf-7be1f8748020",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(chrom_data, output_folder_chrom, 'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d942cf3-6ab9-47b8-b287-28fcdd758bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(chrom_data, output_folder_chrom, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0ee1e-669b-4a87-8c40-0292b97c0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(chrom_data, output_folder_chrom, 'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9dd10-283e-4603-80b7-d6e375e46bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(chrom_data, output_folder_chrom, 'p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c392bde6-69eb-460e-8e37-12b2f653b1c1",
   "metadata": {},
   "source": [
    "## Trying with the most important features\n",
    "### Chromosome data ðŸ”²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607e6155-7c02-4684-90be-1cf086c4f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    classes_before = set(chrom_data['Domain to species'].unique())\n",
    "    print(f\"Before filtering, number of classes: {len(chrom_data['Domain to species'].value_counts())}\")    \n",
    "    chrom_data_filtered = chrom_data.dropna(subset=['All'], axis=0)\n",
    "    chrom_data_filtered = chrom_data_filtered[(chrom_data_filtered['All'] != '') & (chrom_data_filtered['All'] != 'Bacteria')]\n",
    "    chrom_data_filtered = chrom_data_filtered[(chrom_data_filtered.iloc[:, :492] != 0).any(axis=1)]\n",
    "    print(f\"After filtering, number of classes: {len(chrom_data_filtered['Domain to species'].value_counts())}\")\n",
    "    classes_after = set(chrom_data_filtered['Domain to species'].unique())\n",
    "    dropped_classes = classes_before - classes_after\n",
    "    if dropped_classes:\n",
    "        print(f\"Dropped classes: {dropped_classes}\")\n",
    "    else:\n",
    "        print(\"No classes were dropped.\")\n",
    "    return chrom_data_filtered\n",
    "\n",
    "def filter_out_n(data: pd.DataFrame, column_name: str, n: int) -> pd.DataFrame:\n",
    "    print(f\"Before filtering, number of classes: {len(chrom_data[column_name].value_counts())}\")\n",
    "    counts = data[column_name].value_counts()\n",
    "    classes = counts[counts > n].index\n",
    "    filtered_chrom_data = chrom_data[chrom_data[column_name].isin(classes)]\n",
    "    filtered_chrom_data = filtered_chrom_data.dropna(subset=[column_name], axis=0)\n",
    "    print(f\"After filtering, number of classes: {len(filtered_chrom_data[column_name].value_counts())}\")\n",
    "\n",
    "    return filtered_chrom_data\n",
    "\n",
    "def plot_confusion_matrix(y_true: pd.Series, y_pred: pd.Series, model, title: str, target: str):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu', xticklabels=model.classes_, yticklabels=model.classes_, cbar=True)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.title(f'{title} - Accuracy: {accuracy_score(y_true, y_pred):.2f}')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(os.path.join(output_folder_chrom, f'{target}_confusion_mat_150.png'), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_train_test_distribution(y_train: pd.Series, y_test: pd.Series, target: str):\n",
    "    print(\"Plotting the distribution of train and test sets\")\n",
    "    train_species_counts = y_train.value_counts()\n",
    "    test_species_counts = y_test.value_counts()\n",
    "    \n",
    "    categories = pd.concat([y_train, y_test]).value_counts().index\n",
    "    train_counts = y_train.value_counts().reindex(categories, fill_value=0)\n",
    "    test_counts = y_test.value_counts().reindex(categories, fill_value=0)\n",
    "    \n",
    "    indices = range(len(categories))\n",
    "    bar_width = 0.4 \n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar([i - bar_width / 2 for i in indices], train_counts, width=bar_width, color='blue', alpha=0.5, label='Train')\n",
    "    plt.bar([i + bar_width / 2 for i in indices], test_counts, width=bar_width, color='red', alpha=0.5, label='Test')\n",
    "    \n",
    "    plt.xticks(indices, categories, rotation=90)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_feature_importance(model: RandomForestClassifier, X: pd.DataFrame, target: str, top_n: int = 30):\n",
    "    \"\"\"Plot the feature importance of the model with color-coded bars by methylation type.\n",
    "    \n",
    "    Parameters:\n",
    "    - model (RandomForestClassifier): Trained model.\n",
    "    - X (pd.DataFrame): Data frame with the features.\n",
    "    - target (str): Target column.\n",
    "    - top_n (int): Number of top features to plot.\n",
    "    \"\"\"\n",
    "    methylation_colors = {\n",
    "        'm6A': 'skyblue',\n",
    "        'm4C': 'lightcoral',\n",
    "        'modified_base': 'lightgreen',\n",
    "        'other': 'gray'\n",
    "    }\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    top_indices = indices[:top_n]\n",
    "    top_features = X.columns[top_indices]\n",
    "\n",
    "    def get_color(feature_name):\n",
    "        if 'm6A' in feature_name:\n",
    "            return methylation_colors['m6A']\n",
    "        elif 'm4C' in feature_name:\n",
    "            return methylation_colors['m4C']\n",
    "        elif 'modified_base' in feature_name:\n",
    "            return methylation_colors['modified_base']\n",
    "        else:\n",
    "            return methylation_colors['other']\n",
    "\n",
    "    bar_colors = [get_color(feature) for feature in top_features]\n",
    "\n",
    "    # Vertical bar plot\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.bar(range(top_n), importances[top_indices], align='center', color=bar_colors)\n",
    "    plt.xticks(range(top_n), top_features, rotation=45, ha='right', fontsize=10)\n",
    "    plt.title(f\"Feature Importance of Top {top_n} Features with Target {target}\", fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Horizontal bar plot\n",
    "    fig, ax = plt.subplots(figsize=(20, max(5, top_n // 3)))\n",
    "    ax.barh(range(top_n), importances[top_indices], color=bar_colors)\n",
    "    ax.set_yticks(range(top_n))\n",
    "    ax.set_yticklabels(top_features, fontsize=8)\n",
    "    ax.set_ylim(-0.5, top_n - 0.5) \n",
    "\n",
    "    ax.set_xlim(0, max(importances[top_indices]) * 1.05)\n",
    "\n",
    "    plt.title(f\"Feature Importance of Top {top_n} Features with Target {target}\", fontsize=20)\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.save\n",
    "    plt.savefig(os.path.join(output_folder_chrom, f'{target}_features.png'))\n",
    "    plt.show()\n",
    "\n",
    "def train_test_model(df: pd.DataFrame, target: str, n:int):\n",
    "    \n",
    "    print(f\"Training the model with target: {target}\")\n",
    "    filtered_chrom_data = clean_data(df)\n",
    "    filtered_chrom_data = filter_out_n(filtered_chrom_data, target, 10)\n",
    "    \n",
    "    X = filtered_chrom_data.iloc[:, :492]\n",
    "    y = filtered_chrom_data[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)\n",
    "    plot_train_test_distribution(y_train, y_test, target)\n",
    "\n",
    "    model = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    #plot_confusion_matrix(y_train, y_train_pred, model, 'Train Set', target)\n",
    "    #plot_confusion_matrix(y_test, y_test_pred, model, 'Test Set', target)\n",
    "\n",
    "    plot_feature_importance(model, X, target, top_n=n)\n",
    "\n",
    "    metrics = pd.DataFrame({\n",
    "        'Accuracy Train': [accuracy_score(y_train, y_train_pred)],\n",
    "        'Accuracy Test': [accuracy_score(y_test, y_test_pred)],\n",
    "        'Precision': [precision_score(y_test, y_test_pred, average='weighted', zero_division=0)],\n",
    "        'Recall': [recall_score(y_test, y_test_pred, average='weighted', zero_division=0)],\n",
    "        'F1 Score': [f1_score(y_test, y_test_pred, average='weighted', zero_division=0)]\n",
    "    })\n",
    "    print(f\"Metrics for target {target} with all features\")\n",
    "    print(metrics)\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    top_n = n\n",
    "    top_features_indices = np.argsort(importances)[::-1][:top_n]\n",
    "    X_train_top = X_train.iloc[:, top_features_indices]\n",
    "    X_test_top = X_test.iloc[:, top_features_indices]\n",
    "\n",
    "    model_top = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "    model_top.fit(X_train_top, y_train)\n",
    "\n",
    "    y_train_pred = model_top.predict(X_train_top)\n",
    "    y_test_pred = model_top.predict(X_test_top)\n",
    "\n",
    "    plot_confusion_matrix(y_train, y_train_pred, model_top, 'Train Set', target)\n",
    "    plot_confusion_matrix(y_test, y_test_pred, model_top, 'Test Set', target)\n",
    "\n",
    "\n",
    "    metrics = pd.DataFrame({\n",
    "        'Accuracy Train': [accuracy_score(y_train, y_train_pred)],\n",
    "        'Accuracy Test': [accuracy_score(y_test, y_test_pred)],\n",
    "        'Precision': [precision_score(y_test, y_test_pred, average='weighted', zero_division=0)],\n",
    "        'Recall': [recall_score(y_test, y_test_pred, average='weighted', zero_division=0)],\n",
    "        'F1 Score': [f1_score(y_test, y_test_pred, average='weighted', zero_division=0)]\n",
    "    })\n",
    "    print(f\"Metrics for target {target} with top {n} features\")\n",
    "    print(metrics)\n",
    "\n",
    "    return y_test, y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44025852-c107-48f1-afc4-522e95c2f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(chrom_data, 'Domain to species', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8087b5cf-5fcd-4d35-a833-69fa5fd4d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(chrom_data, 'Domain to species', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1671a30b-bed4-415b-b030-d992b0174c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(chrom_data, 'Domain to species', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337d498-2009-4634-bf21-a79e6cb43c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(chrom_data, 'Domain to species', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229d56d2-5d4c-4e38-b678-ccceb6fc29c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(chrom_data, 'Domain to species', 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3eb625-27ae-47f8-b1e9-30a2cb40ddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(chrom_data, 'Domain to species', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d564c-8350-4f3d-b65c-d5be1eab4215",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(chrom_data, 'Domain to species', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b46a03c-78c7-4a27-9aba-b501fa0d5411",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(chrom_data, 'Domain to species', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c381480c-e6ba-4252-bbae-dae50f40c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(chrom_data, 'Domain to species', 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d2e898-1077-4bc8-8ff9-87846dcf1a6f",
   "metadata": {},
   "source": [
    "## Continue with most important features (150)\n",
    "### All data ðŸ’ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791fc52-e818-4f39-a6aa-a0f3117fc35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    classes_before = set(data['Domain to species'].unique())\n",
    "    print(f\"Before filtering, number of classes: {len(data['Domain to species'].value_counts())}\")    \n",
    "    data_filtered = data.dropna(subset=['All'], axis=0)\n",
    "    data_filtered = data_filtered[(data_filtered['All'] != '') & (data_filtered['All'] != 'Bacteria')]\n",
    "    data_filtered = data_filtered[(data_filtered.iloc[:, :492] != 0).any(axis=1)]\n",
    "    print(f\"After filtering, number of classes: {len(data_filtered['Domain to species'].value_counts())}\")\n",
    "    classes_after = set(data_filtered['Domain to species'].unique())\n",
    "    dropped_classes = classes_before - classes_after\n",
    "    if dropped_classes:\n",
    "        print(f\"Dropped classes: {dropped_classes}\")\n",
    "    else:\n",
    "        print(\"No classes were dropped.\")\n",
    "    return data_filtered\n",
    "\n",
    "def filter_out_n(data: pd.DataFrame, column_name: str, n: int) -> pd.DataFrame:\n",
    "    print(f\"Before filtering, number of classes: {len(data[column_name].value_counts())}\")\n",
    "    counts = data[column_name].value_counts()\n",
    "    classes = counts[counts > n].index\n",
    "    filtered_data = data[data[column_name].isin(classes)]\n",
    "    filtered_data = filtered_data.dropna(subset=[column_name], axis=0)\n",
    "    print(f\"After filtering, number of classes: {len(filtered_data[column_name].value_counts())}\")\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "def plot_confusion_matrix(y_true: pd.Series, y_pred: pd.Series, model, title: str, target: str):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu', xticklabels=model.classes_, yticklabels=model.classes_, cbar=True)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.title(f'{title} - Accuracy: {accuracy_score(y_true, y_pred):.2f}')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(os.path.join(output_folder, f'{target}_confusion_mat_150.png'), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_train_test_distribution(y_train: pd.Series, y_test: pd.Series, target: str):\n",
    "    print(\"Plotting the distribution of train and test sets\")\n",
    "    train_species_counts = y_train.value_counts()\n",
    "    test_species_counts = y_test.value_counts()\n",
    "    \n",
    "    categories = pd.concat([y_train, y_test]).value_counts().index\n",
    "    train_counts = y_train.value_counts().reindex(categories, fill_value=0)\n",
    "    test_counts = y_test.value_counts().reindex(categories, fill_value=0)\n",
    "    \n",
    "    indices = range(len(categories))\n",
    "    bar_width = 0.4 \n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar([i - bar_width / 2 for i in indices], train_counts, width=bar_width, color='blue', alpha=0.5, label='Train')\n",
    "    plt.bar([i + bar_width / 2 for i in indices], test_counts, width=bar_width, color='red', alpha=0.5, label='Test')\n",
    "    \n",
    "    plt.xticks(indices, categories, rotation=90)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_feature_importance(model: RandomForestClassifier, X: pd.DataFrame, target: str, top_n: int = 30, output_dir: str = None):\n",
    "    \"\"\"Plot the feature importance of the model and save the top features to a file.\n",
    "    \n",
    "    Parameters:\n",
    "    - model (RandomForestClassifier): Trained model.\n",
    "    - X (pd.DataFrame): Data frame with the features.\n",
    "    - target (str): Target column.\n",
    "    - top_n (int): Number of top features to plot.\n",
    "    - output_dir (str): Path to the output directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if output directory is provided and exists, if not, create it\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Calculate feature importances and sort\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]  # Sort feature importances in descending order\n",
    "    \n",
    "    # Get the top_n features\n",
    "    top_indices = indices[:top_n]\n",
    "    top_features = pd.DataFrame({\n",
    "        'Feature': X.columns[top_indices],\n",
    "        'Importance': importances[top_indices]\n",
    "    })\n",
    "    \n",
    "    # Save the top features DataFrame to a CSV file\n",
    "    if output_dir:\n",
    "        top_features_path = os.path.join(output_dir, f'{target.replace(\" \", \"_\")}_top150_features.csv')\n",
    "        top_features.to_csv(top_features_path, index=False)\n",
    "        print(f\"Top features saved as {top_features_path}\")\n",
    "    \n",
    "    # Plot the feature importances\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.bar(range(top_n), importances[top_indices], align='center', color='skyblue')\n",
    "    plt.xticks(range(top_n), X.columns[top_indices], rotation=45, ha='right', fontsize=10)\n",
    "    plt.title(f\"Feature Importance of {top_n} Features with Target {target}\", fontsize=20)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot\n",
    "    if output_dir:\n",
    "        output_name = f'{target.replace(\" \", \"_\")}_feature_importance_top150.png'\n",
    "        output_path = os.path.join(output_dir, output_name)\n",
    "        plt.savefig(output_path)\n",
    "        print(f\"Feature importance plot saved as {output_path}\")\n",
    "    \n",
    "    # Close the plot to free memory\n",
    "    plt.close()\n",
    "\n",
    "def train_test_model(df: pd.DataFrame, target: str, n:int):\n",
    "    \n",
    "    print(f\"Training the model with target: {target}\")\n",
    "    filtered_data = clean_data(df)\n",
    "    filtered_data = filter_out_n(filtered_data, target, 10)\n",
    "    \n",
    "    X = filtered_data.iloc[:, :492]\n",
    "    y = filtered_data[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)\n",
    "    plot_train_test_distribution(y_train, y_test, target)\n",
    "\n",
    "    model = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    #plot_confusion_matrix(y_train, y_train_pred, model, 'Train Set', target)\n",
    "    #plot_confusion_matrix(y_test, y_test_pred, model, 'Test Set', target)\n",
    "\n",
    "    plot_feature_importance(model, X, target, top_n=n, output_dir='RF_HAMBI')\n",
    "\n",
    "    metrics = pd.DataFrame({\n",
    "        'Accuracy Train': [accuracy_score(y_train, y_train_pred)],\n",
    "        'Accuracy Test': [accuracy_score(y_test, y_test_pred)],\n",
    "        'Precision': [precision_score(y_test, y_test_pred, average='weighted', zero_division=0)],\n",
    "        'Recall': [recall_score(y_test, y_test_pred, average='weighted', zero_division=0)],\n",
    "        'F1 Score': [f1_score(y_test, y_test_pred, average='weighted', zero_division=0)]\n",
    "    })\n",
    "    print(f\"Metrics for target {target} with all features\")\n",
    "    print(metrics)\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    top_n = n\n",
    "    top_features_indices = np.argsort(importances)[::-1][:top_n]\n",
    "    X_train_top = X_train.iloc[:, top_features_indices]\n",
    "    X_test_top = X_test.iloc[:, top_features_indices]\n",
    "\n",
    "    model_top = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "    model_top.fit(X_train_top, y_train)\n",
    "\n",
    "    y_train_pred = model_top.predict(X_train_top)\n",
    "    y_test_pred = model_top.predict(X_test_top)\n",
    "\n",
    "    plot_confusion_matrix(y_train, y_train_pred, model_top, 'Train Set', target)\n",
    "    plot_confusion_matrix(y_test, y_test_pred, model_top, 'Test Set', target)\n",
    "\n",
    "\n",
    "    metrics = pd.DataFrame({\n",
    "        'Accuracy Train': [accuracy_score(y_train, y_train_pred)],\n",
    "        'Accuracy Test': [accuracy_score(y_test, y_test_pred)],\n",
    "        'Precision': [precision_score(y_test, y_test_pred, average='weighted', zero_division=0)],\n",
    "        'Recall': [recall_score(y_test, y_test_pred, average='weighted', zero_division=0)],\n",
    "        'F1 Score': [f1_score(y_test, y_test_pred, average='weighted', zero_division=0)]\n",
    "    })\n",
    "    print(f\"Metrics for target {target} with top {n} features\")\n",
    "    print(metrics)\n",
    "\n",
    "    return y_test, y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ca355-c750-470d-a6e9-6ce3d56e319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/scratch/project_2006608/Methylation/notebooks/RF_HAMBI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499ddca-eac7-4873-9eb4-e427ba72452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, 'Domain to species', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159af06-3c4d-4e85-9677-4f3b95b74882",
   "metadata": {},
   "source": [
    "## View the stats of the different data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1ffce8-3efb-4b2f-bdfe-bf5f040fb634",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_row1 = data.shape[0]\n",
    "count_row2 = len(data.value_counts())\n",
    "count_row3 = chrom_data.shape[0]\n",
    "count_row4 = len(chrom_data.value_counts())\n",
    "print(f\"All data: {count_row1}\")\n",
    "print(f\"All data, without NA: {count_row2}\")\n",
    "print(f\"Chromosomes data: {count_row3}\")\n",
    "print(f\"Chromosomes, without NA: {count_row4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f235af88-add7-463e-ab7d-6df8ee06f211",
   "metadata": {},
   "source": [
    "## Trying shorter range of the sequence\n",
    "### Less noise ðŸ”·\n",
    "#### -10...0...10\n",
    "#### -5...0...5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964cb7da-8121-454f-b749-24bcb368eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '/scratch/project_2006608/Methylation/notebooks/RF_HAMBI_short'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c572f02e-c612-44a8-a03e-0776ea807b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_short_5 = pd.read_csv(\"/scratch/project_2006608/Methylation/HAMBI_data/merged_data_short_5.tsv\", \n",
    "                         sep=\"\\t\", index_col=0, header=0,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03627bda-e4f0-49de-8a5e-666ff9ac82d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_short_10 = pd.read_csv(\"/scratch/project_2006608/Methylation/HAMBI_data/merged_data_short_10.tsv\", \n",
    "                         sep=\"\\t\", index_col=0, header=0,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1736595-1694-4229-8a79-a594a6b9dfd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_short_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9624644-c3d2-4478-a153-ee127d043c16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_short_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdd30d-1d07-4197-b376-030f5a74ade0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dim = pd.DataFrame(data_short_10)\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5bcf2-9d06-4206-b767-8e4ecddb325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_short_10['Domain to species'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dfd8ae-9b5c-478e-be68-5818e125b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_short_10['Domain to species'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abe27a1-557d-4ef7-a38c-9aee1daa2c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_short_10.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa3c6a-91a5-4dca-8ff1-c32dc133e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_short_10['Domain to species'].value_counts(dropna=False))\n",
    "len(data_short_10['s'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadc33e8-0da2-4bdd-8c92-e0d3b92d40ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/scratch/project_2006608/Methylation/notebooks/RF_HAMBI_short'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defc0d26-9ba8-407c-8fda-3b22787a01a9",
   "metadata": {},
   "source": [
    "## Random forest classifier \n",
    "### Less noise ðŸ”·\n",
    "#### -10...0...10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7b9a8-8c24-45b7-88e6-c54125c18623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    classes_before = set(data_short_10['s'].unique())\n",
    "    print(f\"before filtering number of classes {len(data_short_10['s'].value_counts())}\")   \n",
    "    data_short_filtered = data_short_10.dropna(subset=['All'], axis=0)\n",
    "    data_short_filtered = data_short_filtered[(data_short_filtered['All'] != '') & (data_short_filtered['All'] != 'Bacteria')]\n",
    "    data_short_filtered = data_short_filtered[(data_short_filtered.iloc[:, :254] != 0).any(axis=1)]\n",
    "    print(f\"after filtering number of classes {len(data_short_filtered['s'].value_counts())}\")\n",
    "    classes_after = set(data_short_filtered['s'].unique())\n",
    "    dropped_classes = classes_before - classes_after\n",
    "    if dropped_classes:\n",
    "        print(f\"Dropped classes: {dropped_classes}\")\n",
    "    else:\n",
    "        print(\"No classes were dropped.\")\n",
    "    return data_short_filtered\n",
    "\n",
    "def filter_out_n(data_short: pd.DataFrame, column_name: str, n: int) -> pd.DataFrame:\n",
    "    \"\"\"Filter out the contigs that have less than n samples in the given column.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): Data frame with the data.\n",
    "    - column_name (str): Column name to filter out.\n",
    "    - n (int): Minimum number of samples.\n",
    "    \"\"\"\n",
    "    print(f\"before filtering number of classes {len(data_short_10[column_name].value_counts())}\")\n",
    "    counts = data_short_10[column_name].value_counts()\n",
    "    classes = counts[counts > n].index\n",
    "    filtered_data_short = data_short_10[data_short_10[column_name].isin(classes)]\n",
    "    filtered_data_short = filtered_data_short.dropna(subset=[column_name], axis=0)\n",
    "    print(f\"after filtering number of classes {len(filtered_data_short[column_name].value_counts())}\")\n",
    "\n",
    "    return filtered_data_short\n",
    "\n",
    "def plot_confusion_matrix(y_true: pd.Series, y_pred: pd.Series, model: RandomForestClassifier, title: str, output_dir: str, target: str):\n",
    "    \"\"\"Plot the confusion matrix for the given true and predicted values.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true (pd.Series): True labels.\n",
    "    - y_pred (pd.Series): Predicted labels.\n",
    "    - model (RandomForestClassifier): Trained model.\n",
    "    - title (str): Title of the plot.\n",
    "    - output_dir (str): Path to the output directory where the plot will be saved.\n",
    "    - target (str): Target column.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(50, 50))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu', xticklabels=model.classes_, yticklabels=model.classes_, cbar=True,\n",
    "                annot_kws={\"size\": 50})\n",
    "    plt.xticks(rotation=90, fontsize=40, fontstyle='italic'\n",
    "               #horizontalalignment='left', verticalalignment='baseline'\n",
    "              )\n",
    "    plt.yticks(rotation=0, fontsize=40, fontstyle='italic')\n",
    "    plt.title(f'{title} - Accuracy: {accuracy_score(y_true, y_pred):.2f}', fontsize=80)\n",
    "    plt.xlabel('Predicted Labels', fontsize=50)\n",
    "    plt.ylabel('True Labels', fontsize=50)\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    title = title.replace(' ', '_')\n",
    "    plt.savefig(os.path.join(output_dir, f'{title}_short_10.png'))\n",
    "    plt.savefig(os.path.join(output_dir, f'{title}_short_10.jpg'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_train_test_distribution(y_train: pd.Series, y_test: pd.Series, output_folder_short: str, target: str):\n",
    "    \"\"\"Plot the distribution of the train and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_train (pd.Series): True labels of the train set.\n",
    "    - y_test (pd.Series): True labels of the test set.\n",
    "    - output_dir (str): Path to the output directory.\n",
    "    \"\"\"\n",
    "    print(\"Plotting the distribution\")\n",
    "    train_species_counts = y_train.value_counts()\n",
    "    test_species_counts = y_test.value_counts()\n",
    "    \n",
    "    print(\"Number of samples in each species in the train set:\")\n",
    "    print(train_species_counts)\n",
    "    print(\"\\nNumber of samples in each species in the test set:\")\n",
    "    print(test_species_counts)\n",
    "    num_classes = len(set(y_train.unique()).union(set(y_test.unique())))\n",
    "    \n",
    "    width = max(12, num_classes * 0.6)\n",
    "    height = max(8, num_classes * 0.8)\n",
    "    \n",
    "    plt.figure(figsize=(width, height))\n",
    "    \n",
    "    categories = pd.concat([y_train, y_test]).value_counts().index\n",
    "    train_counts = y_train.value_counts().reindex(categories, fill_value=0)\n",
    "    test_counts = y_test.value_counts().reindex(categories, fill_value=0)\n",
    "    \n",
    "    indices = range(len(categories))\n",
    "    bar_width = 0.4 \n",
    "\n",
    "    plt.bar([i - bar_width / 2 for i in indices], train_counts, width=bar_width, color='blue', alpha=0.5, label='Train')\n",
    "    plt.bar([i + bar_width / 2 for i in indices], test_counts, width=bar_width, color='red', alpha=0.5, label='Test')\n",
    "    \n",
    "    plt.xticks(indices, categories, rotation=90, fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "    target = target.replace(' ', '_')\n",
    "    plt.savefig(os.path.join(output_dir, f'{target}_train_test_distribution_short_10.png'), bbox_inches='tight')\n",
    "\n",
    "    plt.savefig(os.path.join(output_dir, f'{target}_train_test_distribution_short_10.jpg'))\n",
    "    plt.show()\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(model: RandomForestClassifier, X: pd.DataFrame, target:str, top_n: int = 30, output_folder_short: str = None):\n",
    "    \"\"\"Plot the feature importance of the model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model (RandomForestClassifier): Trained model.\n",
    "    - X (pd.DataFrame): Data frame with the features.\n",
    "    - target (str): Target column.\n",
    "    - top_n (int): Number of top features to plot.\n",
    "    - output_dir (str): Path to the output directory.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    top_indices = indices[:top_n]\n",
    "    plt.bar(range(top_n), importances[top_indices], align='center', color='skyblue')\n",
    "    plt.xticks(range(top_n), X.columns[top_indices], rotation=45, ha='right', fontsize=10)\n",
    "    plt.title(f\"Feature Importance of {top_n} features with target {target}\", fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    output_name = f'{target.replace(\" \", \"_\")}_feature_importance_short_10.png'\n",
    "    plt.savefig(os.path.join(output_dir, output_name))\n",
    "    plt.savefig(os.path.join(output_dir, output_name.replace('.png', '.jpg')))\n",
    "    plt.close()\n",
    "\n",
    "def train_test_model(df: pd.DataFrame, output_folder_short: str, target: str):\n",
    "    \"\"\"Train and test the random forest classifier.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Data frame with the data.\n",
    "    - output_folder (str): Path to the output directory to save the results for the model plots\n",
    "    - target (str): Target column.\n",
    "    \"\"\"\n",
    "    print(f\"Training the model with target: {target}\")\n",
    "    filtered_data_short = clean_data(df)\n",
    "    filtered_data_short = filter_out_n(filtered_data_short, target, 10)\n",
    "    \n",
    "    X_DS = filtered_data_short.iloc[:, :254] \n",
    "    y_DS = filtered_data_short[target]\n",
    "\n",
    "    X_train_DS, X_test_DS, y_train_DS, y_test_DS = train_test_split(X_DS, y_DS, test_size=0.2, random_state=seed, stratify=y_DS)\n",
    "    plot_train_test_distribution(y_train_DS, y_test_DS, output_folder_short, target)\n",
    "    model = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "    model.fit(X_train_DS, y_train_DS)\n",
    "\n",
    "    y_train_pred_DS = model.predict(X_train_DS)\n",
    "    y_test_pred_DS = model.predict(X_test_DS)\n",
    "\n",
    "    plot_confusion_matrix(y_train_DS, y_train_pred_DS, model, f'Train Set with target {target}', output_folder_short, target)\n",
    "    plot_confusion_matrix(y_test_DS, y_test_pred_DS, model, f'Test Set with target {target}', output_folder_short, target)\n",
    "\n",
    "    plot_feature_importance(model, X_DS, target, 30, output_folder_short)\n",
    "\n",
    "    metrics = pd.DataFrame({\n",
    "            'Accuracy Train': [accuracy_score(y_train_DS, y_train_pred_DS)],\n",
    "            'Accuracy Test': [accuracy_score(y_test_DS, y_test_pred_DS)],\n",
    "            'Precision': [precision_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)],\n",
    "            'Recall': [recall_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)],\n",
    "            'F1 Score': [f1_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)]\n",
    "        })\n",
    "    \n",
    "    metrics.to_csv(os.path.join(output_folder_short, f'{target.replace(\" \", \"_\")}_metrics_short_10.tsv'), sep='\\t')\n",
    "    print(f\"Metrics for target {target}\")\n",
    "    print(metrics)\n",
    "\n",
    "    if accuracy_score(y_test_DS, y_test_pred_DS) > 0.7:\n",
    "        print(f\"Model trained with accuracy: {accuracy_score(y_test_DS, y_test_pred_DS)}\")\n",
    "        model_file_path = os.path.join(output_folder, f'{target.replace(\" \", \"_\")}_model_short_10.joblib')\n",
    "        print(f\"Saving the model to {model_file_path}\")\n",
    "        joblib.dump(model, model_file_path)\n",
    "    else:\n",
    "        print(f\"Model trained with accuracy: {accuracy_score(y_test_DS, y_test_pred_DS)}\")\n",
    "    return y_test_DS, y_test_pred_DS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6613fbc4-4808-491a-9494-ae2e286339cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_short = '/scratch/project_2006608/Methylation/notebooks/RF_HAMBI_short'\n",
    "if not os.path.exists(output_folder_short):\n",
    "    os.makedirs(output_folder_short)\n",
    "\n",
    "y_test_DS, y_test_pred_DS = train_test_model(data_short_10, output_folder_short, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef104eca-5688-4734-8abd-3c5b445a5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(y_test_pred_DS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a7a7a-f1ff-4832-b500-01434da6c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data_short_10, output_folder_short, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43b955-bfe4-4029-903e-6221e7ff11d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data_short_10, output_folder_short, 'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3f0290-94e9-4db7-b648-ce05c2b60fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data_short_10, output_folder_short, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a5c13c-fa46-4a5f-b8f4-1463139875d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data_short_10, output_folder_short, 'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941add41-863e-42c1-9d85-ddba2faf021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data_short_10, output_folder_short, 'p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9034a06b-2c10-48ed-8851-3ab0f5ae739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    classes_before = set(data_short_5['s'].unique())\n",
    "    print(f\"before filtering number of classes {len(data_short_5['s'].value_counts())}\")   \n",
    "    data_short_filtered = data_short_5.dropna(subset=['All'], axis=0)\n",
    "    data_short_filtered = data_short_filtered[(data_short_filtered['All'] != '') & (data_short_filtered['All'] != 'Bacteria')]\n",
    "    data_short_filtered = data_short_filtered[(data_short_filtered.iloc[:, :132] != 0).any(axis=1)]\n",
    "    print(f\"after filtering number of classes {len(data_short_filtered['s'].value_counts())}\")\n",
    "    classes_after = set(data_short_filtered['s'].unique())\n",
    "    dropped_classes = classes_before - classes_after\n",
    "    if dropped_classes:\n",
    "        print(f\"Dropped classes: {dropped_classes}\")\n",
    "    else:\n",
    "        print(\"No classes were dropped.\")\n",
    "    return data_short_filtered\n",
    "\n",
    "def filter_out_n(data_short: pd.DataFrame, column_name: str, n: int) -> pd.DataFrame:\n",
    "    \"\"\"Filter out the contigs that have less than n samples in the given column.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): Data frame with the data.\n",
    "    - column_name (str): Column name to filter out.\n",
    "    - n (int): Minimum number of samples.\n",
    "    \"\"\"\n",
    "    print(f\"before filtering number of classes {len(data_short_5[column_name].value_counts())}\")\n",
    "    counts = data_short_5[column_name].value_counts()\n",
    "    classes = counts[counts > n].index\n",
    "    filtered_data_short = data_short_5[data_short_5[column_name].isin(classes)]\n",
    "    filtered_data_short = filtered_data_short.dropna(subset=[column_name], axis=0)\n",
    "    print(f\"after filtering number of classes {len(filtered_data_short[column_name].value_counts())}\")\n",
    "\n",
    "    return filtered_data_short\n",
    "\n",
    "def plot_confusion_matrix(y_true: pd.Series, y_pred: pd.Series, model: RandomForestClassifier, title: str, output_dir: str, target: str):\n",
    "    \"\"\"Plot the confusion matrix for the given true and predicted values.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true (pd.Series): True labels.\n",
    "    - y_pred (pd.Series): Predicted labels.\n",
    "    - model (RandomForestClassifier): Trained model.\n",
    "    - title (str): Title of the plot.\n",
    "    - output_dir (str): Path to the output directory where the plot will be saved.\n",
    "    - target (str): Target colu<mn.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(50, 50))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu', xticklabels=model.classes_, yticklabels=model.classes_, cbar=True,\n",
    "                annot_kws={\"size\": 50})\n",
    "    plt.xticks(rotation=90, fontsize=40, fontstyle='italic'\n",
    "               #horizontalalignment='left', verticalalignment='baseline'\n",
    "              )\n",
    "    plt.yticks(rotation=0, fontsize=40, fontstyle='italic')\n",
    "    plt.title(f'{title} - Accuracy: {accuracy_score(y_true, y_pred):.2f}', fontsize=80)\n",
    "    plt.xlabel('Predicted Labels', fontsize=50)\n",
    "    plt.ylabel('True Labels', fontsize=50)\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    title = title.replace(' ', '_')\n",
    "    plt.savefig(os.path.join(output_dir, f'{title}_short_5.png'))\n",
    "    plt.savefig(os.path.join(output_dir, f'{title}_short_5.jpg'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_train_test_distribution(y_train: pd.Series, y_test: pd.Series, output_folder_short: str, target: str):\n",
    "    \"\"\"Plot the distribution of the train and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_train (pd.Series): True labels of the train set.\n",
    "    - y_test (pd.Series): True labels of the test set.\n",
    "    - output_dir (str): Path to the output directory.\n",
    "    \"\"\"\n",
    "    print(\"Plotting the distribution\")\n",
    "    train_species_counts = y_train.value_counts()\n",
    "    test_species_counts = y_test.value_counts()\n",
    "    \n",
    "    print(\"Number of samples in each species in the train set:\")\n",
    "    print(train_species_counts)\n",
    "    print(\"\\nNumber of samples in each species in the test set:\")\n",
    "    print(test_species_counts)\n",
    "    num_classes = len(set(y_train.unique()).union(set(y_test.unique())))\n",
    "    \n",
    "    width = max(12, num_classes * 0.6)\n",
    "    height = max(8, num_classes * 0.8)\n",
    "    \n",
    "    plt.figure(figsize=(width, height))\n",
    "    \n",
    "    categories = pd.concat([y_train, y_test]).value_counts().index\n",
    "    train_counts = y_train.value_counts().reindex(categories, fill_value=0)\n",
    "    test_counts = y_test.value_counts().reindex(categories, fill_value=0)\n",
    "    \n",
    "    indices = range(len(categories))\n",
    "    bar_width = 0.4 \n",
    "\n",
    "    plt.bar([i - bar_width / 2 for i in indices], train_counts, width=bar_width, color='blue', alpha=0.5, label='Train')\n",
    "    plt.bar([i + bar_width / 2 for i in indices], test_counts, width=bar_width, color='red', alpha=0.5, label='Test')\n",
    "    \n",
    "    plt.xticks(indices, categories, rotation=90, fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "    target = target.replace(' ', '_')\n",
    "    plt.savefig(os.path.join(output_dir, f'{target}_train_test_distribution_short_5.png'), bbox_inches='tight')\n",
    "\n",
    "    plt.savefig(os.path.join(output_dir, f'{target}_train_test_distribution_short_5.jpg'))\n",
    "    plt.show()\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(model: RandomForestClassifier, X: pd.DataFrame, target:str, top_n: int = 30, output_folder_short: str = None):\n",
    "    \"\"\"Plot the feature importance of the model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model (RandomForestClassifier): Trained model.\n",
    "    - X (pd.DataFrame): Data frame with the features.\n",
    "    - target (str): Target column.\n",
    "    - top_n (int): Number of top features to plot.\n",
    "    - output_dir (str): Path to the output directory.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    top_indices = indices[:top_n]\n",
    "    plt.bar(range(top_n), importances[top_indices], align='center', color='skyblue')\n",
    "    plt.xticks(range(top_n), X.columns[top_indices], rotation=45, ha='right', fontsize=10)\n",
    "    plt.title(f\"Feature Importance of {top_n} features with target {target}\", fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    output_name = f'{target.replace(\" \", \"_\")}_feature_importance_short_5.png'\n",
    "    plt.savefig(os.path.join(output_dir, output_name))\n",
    "    plt.savefig(os.path.join(output_dir, output_name.replace('.png', '.jpg')))\n",
    "    plt.close()\n",
    "\n",
    "def train_test_model(df: pd.DataFrame, output_folder_short: str, target: str):\n",
    "    \"\"\"Train and test the random forest classifier.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Data frame with the data.\n",
    "    - output_folder (str): Path to the output directory to save the results for the model plots\n",
    "    - target (str): Target column.\n",
    "    \"\"\"\n",
    "    print(f\"Training the model with target: {target}\")\n",
    "    filtered_data_short = clean_data(df)\n",
    "    filtered_data_short = filter_out_n(filtered_data_short, target, 10)\n",
    "    \n",
    "    X_DS = filtered_data_short.iloc[:, :132] \n",
    "    y_DS = filtered_data_short[target]\n",
    "\n",
    "    X_train_DS, X_test_DS, y_train_DS, y_test_DS = train_test_split(X_DS, y_DS, test_size=0.2, random_state=seed, stratify=y_DS)\n",
    "    plot_train_test_distribution(y_train_DS, y_test_DS, output_folder_short, target)\n",
    "    model = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "    model.fit(X_train_DS, y_train_DS)\n",
    "\n",
    "    y_train_pred_DS = model.predict(X_train_DS)\n",
    "    y_test_pred_DS = model.predict(X_test_DS)\n",
    "\n",
    "    plot_confusion_matrix(y_train_DS, y_train_pred_DS, model, f'Train Set with target {target}', output_folder_short, target)\n",
    "    plot_confusion_matrix(y_test_DS, y_test_pred_DS, model, f'Test Set with target {target}', output_folder_short, target)\n",
    "\n",
    "    plot_feature_importance(model, X_DS, target, 30, output_folder_short)\n",
    "\n",
    "    metrics = pd.DataFrame({\n",
    "            'Accuracy Train': [accuracy_score(y_train_DS, y_train_pred_DS)],\n",
    "            'Accuracy Test': [accuracy_score(y_test_DS, y_test_pred_DS)],\n",
    "            'Precision': [precision_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)],\n",
    "            'Recall': [recall_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)],\n",
    "            'F1 Score': [f1_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)]\n",
    "        })\n",
    "    \n",
    "    metrics.to_csv(os.path.join(output_folder_short, f'{target.replace(\" \", \"_\")}_metrics_short_5.tsv'), sep='\\t')\n",
    "    print(f\"Metrics for target {target}\")\n",
    "    print(metrics)\n",
    "\n",
    "    if accuracy_score(y_test_DS, y_test_pred_DS) > 0.7:\n",
    "        print(f\"Model trained with accuracy: {accuracy_score(y_test_DS, y_test_pred_DS)}\")\n",
    "        model_file_path = os.path.join(output_folder, f'{target.replace(\" \", \"_\")}_model_short_5.joblib')\n",
    "        print(f\"Saving the model to {model_file_path}\")\n",
    "        joblib.dump(model, model_file_path)\n",
    "    else:\n",
    "        print(f\"Model trained with accuracy: {accuracy_score(y_test_DS, y_test_pred_DS)}\")\n",
    "    return y_test_DS, y_test_pred_DS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88caf4bd-d131-4c50-9cfd-349a2bf8828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_short = '/scratch/project_2006608/Methylation/notebooks/RF_HAMBI_short'\n",
    "if not os.path.exists(output_folder_short):\n",
    "    os.makedirs(output_folder_short)\n",
    "\n",
    "y_test_DS, y_test_pred_DS = train_test_model(data_short_5, output_folder_short, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871e9fd0-f498-4df4-9247-79b8684ad951",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(y_test_pred_DS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6621f7-a7c4-4f5b-bdd7-238b3733715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data_short_5, output_folder_short, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9df211-85e5-4797-b3d6-630f4b574444",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data_short_5, output_folder_short, 'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac09fb46-e5c6-495e-8acf-81228c901a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data_short_5, output_folder_short, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845bcfd6-7f01-463e-be6c-403cc0ab6e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data_short_5, output_folder_short, 'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4710f0ed-0656-42f6-821e-f34b50b790c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data_short_5, output_folder_short, 'p')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
