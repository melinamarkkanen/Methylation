{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d05cf26d-9f98-4db4-96dc-009cfe247c32",
   "metadata": {},
   "source": [
    "# Random Forest for HAMBI data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2031a8a-0129-47d1-b0b3-9816e6fdf5dc",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e6f9ed8-c1e1-4d87-820b-748006821753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "# Set seed\n",
    "seed = 98\n",
    "\n",
    "# Set font\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from copy import copy\n",
    "\n",
    "# List all font names\n",
    "#available_fonts = sorted(set(f.name for f in fm.fontManager.ttflist))\n",
    "#for font in available_fonts:\n",
    "#    print(font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf71140-d23d-4138-b904-9b662322bff2",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55571c29-ad57-42ad-95b8-843c844fd052",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '/scratch/project_2006608/Methylation/notebooks/RF_HAMBI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5015f7d-dc2c-44ec-98ef-9cbb2952f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/scratch/project_2006608/Methylation/HAMBI_data/merged_data.tsv\", sep=\"\\t\", index_col=0, header=0,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dfcb54-f39d-410f-b8dd-995d7435d237",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794fba1a-32fd-491f-a6b7-63ff2d91696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Domain to species'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca63a6e-c0b6-4ba6-ac02-acaa639b841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['Domain to species'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d75ffd-b0c0-4910-b587-4778d5598b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de7f38-634e-4a51-8315-d6bfce567622",
   "metadata": {},
   "source": [
    "## Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ebec8e-0b18-437b-be6a-538d86138728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    classes_before = set(data['s'].unique())\n",
    "    print(f\"before filtering number of classes {len(data['s'].value_counts())}\")   \n",
    "    data_filtered = data.dropna(subset=['All'], axis=0)\n",
    "    data_filtered = data_filtered[(data_filtered['All'] != '') & (data_filtered['All'] != 'Bacteria')]\n",
    "    data_filtered = data_filtered[(data_filtered.iloc[:, :492] != 0).any(axis=1)]\n",
    "    print(f\"after filtering number of classes {len(data_filtered['s'].value_counts())}\")\n",
    "    classes_after = set(data_filtered['s'].unique())\n",
    "    dropped_classes = classes_before - classes_after\n",
    "    if dropped_classes:\n",
    "        print(f\"Dropped classes: {dropped_classes}\")\n",
    "    else:\n",
    "        print(\"No classes were dropped.\")\n",
    "    return data_filtered\n",
    "\n",
    "def filter_out_n(data: pd.DataFrame, column_name: str, n: int) -> pd.DataFrame:\n",
    "    \"\"\"Filter out the contigs that have less than n samples in the given column.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): Data frame with the data.\n",
    "    - column_name (str): Column name to filter out.\n",
    "    - n (int): Minimum number of samples.\n",
    "    \"\"\"\n",
    "    print(f\"before filtering number of classes {len(data[column_name].value_counts())}\")\n",
    "    counts = data[column_name].value_counts()\n",
    "    classes = counts[counts > n].index\n",
    "    filtered_data = data[data[column_name].isin(classes)]\n",
    "    filtered_data = filtered_data.dropna(subset=[column_name], axis=0)\n",
    "    print(f\"after filtering number of classes {len(filtered_data[column_name].value_counts())}\")\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "def plot_confusion_matrix(y_true: pd.Series, y_pred: pd.Series, model: RandomForestClassifier, title: str, output_dir: str, target: str):\n",
    "    \"\"\"Plot the confusion matrix for the given true and predicted values.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true (pd.Series): True labels.\n",
    "    - y_pred (pd.Series): Predicted labels.\n",
    "    - model (RandomForestClassifier): Trained model.\n",
    "    - title (str): Title of the plot.\n",
    "    - output_dir (str): Path to the output directory where the plot will be saved.\n",
    "    - target (str): Target column.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Replace zeros with np.nan to mask them\n",
    "    cm_nan = cm.astype(float)\n",
    "    cm_nan[cm_nan == 0] = np.nan\n",
    "\n",
    "    # Copy the colormap and set the color for NaNs (bad values)\n",
    "    base_cmap = copy(plt.get_cmap(\"YlGnBu\"))\n",
    "    base_cmap.set_bad(color=\"#FFFFF7\")  # lighter color for zero\n",
    "\n",
    "    # Prepare annotation: show numbers except for NaNs (which become empty strings)\n",
    "    annot = np.where(np.isnan(cm_nan), \"\", cm_nan.astype(int).astype(str))\n",
    "    \n",
    "    # For Species\n",
    "    clean_labels = [label.replace(\"_\", \" \") for label in model.classes_]\n",
    "    \n",
    "    plt.figure(figsize=(50, 50))\n",
    "\n",
    "    sns.heatmap(cm_nan, cmap=base_cmap, annot=annot, fmt='',\n",
    "    # For species\n",
    "        xticklabels=clean_labels, yticklabels=clean_labels,\n",
    "        #xticklabels=model.classes_, yticklabels=model.classes_,\n",
    "                cbar=True, annot_kws={\"size\": 60}, cbar_kws={'label': '', 'shrink': 0.8, 'aspect': 30, 'orientation': 'vertical'})\n",
    "    \n",
    "    plt.xticks(rotation = 40, ha='right', fontsize=60, fontstyle='italic')\n",
    "    plt.yticks(rotation=0, fontsize=60, fontstyle='italic')\n",
    "\n",
    "    # Edit legend labels\n",
    "    ax = plt.gca()\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=60)\n",
    "\n",
    "    plt.title(f'{title} - Accuracy: {accuracy_score(y_true, y_pred):.2f}', fontsize=110)\n",
    "    # For species\n",
    "    xticklabels=clean_labels,\n",
    "    yticklabels=clean_labels,\n",
    "    #xticklabels=model.classes_,\n",
    "    #yticklabels=model.classes_,\n",
    "    plt.xlabel('Predicted labels', fontsize=80, fontweight='bold')\n",
    "    plt.ylabel('True labels', fontsize=80, fontweight='bold')\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    title = title.replace(' ', '_')\n",
    "    plt.savefig(os.path.join(output_dir, f'{title}.png'))\n",
    "    plt.savefig(os.path.join(output_dir, f'{title}.svg'))\n",
    "\n",
    "    # Edit when you have chosen the number of features\n",
    "    plt.savefig(os.path.join(output_folder, f'{target}_confusion_mat.png'), bbox_inches='tight')\n",
    "    plt.savefig(os.path.join(output_folder, f'{target}_confusion_mat.svg'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "def plot_train_test_distribution(y_train: pd.Series, y_test: pd.Series, output_dir: str, target: str):\n",
    "    \"\"\"Plot the distribution of the train and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_train (pd.Series): True labels of the train set.\n",
    "    - y_test (pd.Series): True labels of the test set.\n",
    "    - output_dir (str): Path to the output directory.\n",
    "    \"\"\"\n",
    "    print(\"Plotting the distribution\")\n",
    "    train_species_counts = y_train.value_counts()\n",
    "    test_species_counts = y_test.value_counts()\n",
    "    \n",
    "    print(\"Number of samples in each species in the train set:\")\n",
    "    print(train_species_counts)\n",
    "    print(\"\\nNumber of samples in each species in the test set:\")\n",
    "    print(test_species_counts)\n",
    "    num_classes = len(set(y_train.unique()).union(set(y_test.unique())))\n",
    "    \n",
    "    width = max(12, num_classes * 0.6)\n",
    "    height = max(8, num_classes * 0.8)\n",
    "    \n",
    "    plt.figure(figsize=(width, height))\n",
    "    \n",
    "    categories = pd.concat([y_train, y_test]).value_counts().index\n",
    "    train_counts = y_train.value_counts().reindex(categories, fill_value=0)\n",
    "    test_counts = y_test.value_counts().reindex(categories, fill_value=0)\n",
    "    \n",
    "    indices = range(len(categories))\n",
    "    bar_width = 0.4 \n",
    "\n",
    "    # For species\n",
    "    labels = [\"Citrobacter_B_koseri\", \"Pseudomonas_E_putida\", \"Bordetella_avium\", \"Microvirga_lotononidis\",\n",
    "              \"Paracoccus_denitrificans\", \"Comamonas_testosteroni_C\", \"Pseudomonas_E_chlororaphis\", \"Morganella_morganii\",\n",
    "              \"Cupriavidus_oxalaticus\", \"Sphingobium_yanoikuyae\", \"Aeromonas_caviae\"]   \n",
    "    clean_labels = [label.replace(\"_\", \" \") for label in labels]\n",
    "    \n",
    "    plt.bar([i - bar_width / 2 for i in indices], train_counts, width=bar_width, color='blue', alpha=0.5, label='Train')\n",
    "    plt.bar([i + bar_width / 2 for i in indices], test_counts, width=bar_width, color='red', alpha=0.5, label='Test')\n",
    "\n",
    "    # For species\n",
    "    plt.xticks(indices, clean_labels, fontsize=16, fontstyle='italic', rotation = 40, ha='right')\n",
    "    \n",
    "    # Other than species:\n",
    "    #plt.xticks(indices, categories, fontsize=16, fontstyle='italic', rotation = 40, ha='right')\n",
    "    \n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.title(f'Distribution of train and test set data', fontsize=30)\n",
    "    plt.subplots_adjust(bottom=0.3)\n",
    "    \n",
    "    target = target.replace(' ', '_')\n",
    "    plt.savefig(os.path.join(output_dir, f'{target}_train_test_distribution.png'), bbox_inches='tight')\n",
    "    plt.savefig(os.path.join(output_dir, f'{target}_train_test_distribution.svg'))\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_importance(model: RandomForestClassifier, X: pd.DataFrame, target:str, top_n: int = 30, output_dir: str = None):\n",
    "    \"\"\"Plot the feature importance of the model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model (RandomForestClassifier): Trained model.\n",
    "    - X (pd.DataFrame): Data frame with the features.\n",
    "    - target (str): Target column.\n",
    "    - top_n (int): Number of top features to plot.\n",
    "    - output_dir (str): Path to the output directory.\n",
    "    \"\"\"\n",
    "\n",
    "    methylation_colors = {'m6A': '#BF5137',\n",
    "                          'm4C': '#365E46',\n",
    "                          'modified_base': '#ABC7C9',\n",
    "                          'other': 'gray'}\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    top_indices = indices[:top_n]\n",
    "    top_features = X.columns[top_indices]\n",
    "\n",
    "    def get_color(feature_name):\n",
    "        if 'm6A' in feature_name:\n",
    "            return methylation_colors['m6A']\n",
    "        elif 'm4C' in feature_name:\n",
    "            return methylation_colors['m4C']\n",
    "        elif 'modified_base' in feature_name:\n",
    "            return methylation_colors['modified_base']\n",
    "        else:\n",
    "            return methylation_colors['other']\n",
    "\n",
    "    bar_colors = [get_color(feature) for feature in top_features]\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.bar(range(top_n), importances[top_indices], align='center', color=bar_colors)\n",
    "    plt.xticks(range(top_n), X.columns[top_indices], rotation=45, ha='right', fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.title(f\"Top {top_n} features with species\", fontsize=50)\n",
    "    plt.xlim(-0.5, len(top_indices) - 0.5)\n",
    "    plt.tight_layout()\n",
    "    output_name = f'{target.replace(\" \", \"_\")}_feature_importance_colors.png'\n",
    "    plt.savefig(os.path.join(output_dir, f'{target}_feature_importance_colors.png'))\n",
    "    plt.savefig(os.path.join(output_dir, f'{target}_feature_importance_colors.svg'))\n",
    "    plt.close()\n",
    "\n",
    "def train_test_model(df: pd.DataFrame, output_folder: str, target: str):\n",
    "    \"\"\"Train and test the random forest classifier.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Data frame with the data.\n",
    "    - output_folder (str): Path to the output directory to save the results for the model plots\n",
    "    - target (str): Target column.\n",
    "    \"\"\"\n",
    "    print(f\"Training the model with target: {target}\")\n",
    "    filtered_data = clean_data(df)\n",
    "    filtered_data = filter_out_n(filtered_data, target, 10) ###### tätä muokkaa takasin 10\n",
    "    \n",
    "    X_DS = filtered_data.iloc[:, :492] \n",
    "    y_DS = filtered_data[target]\n",
    "\n",
    "    X_train_DS, X_test_DS, y_train_DS, y_test_DS = train_test_split(X_DS, y_DS, test_size=0.2, random_state=seed, stratify=y_DS)\n",
    "    plot_train_test_distribution(y_train_DS, y_test_DS, output_folder, target)\n",
    "    model = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "    model.fit(X_train_DS, y_train_DS)\n",
    "\n",
    "    y_train_pred_DS = model.predict(X_train_DS)\n",
    "    y_test_pred_DS = model.predict(X_test_DS)\n",
    "\n",
    "    # For species\n",
    "    labels = [\"Citrobacter_B_koseri\", \"Pseudomonas_E_putida\", \"Bordetella_avium\", \"Microvirga_lotononidis\",\n",
    "              \"Paracoccus_denitrificans\", \"Comamonas_testosteroni_C\", \"Pseudomonas_E_chlororaphis\", \"Morganella_morganii\",\n",
    "              \"Cupriavidus_oxalaticus\", \"Sphingobium_yanoikuyae\", \"Aeromonas_caviae\"]\n",
    "    clean_labels = [label.replace(\"_\", \" \") for label in labels]\n",
    "\n",
    "    plot_confusion_matrix(y_train_DS, y_train_pred_DS, model, f'Train Set with {target}', output_folder, target)\n",
    "    plot_confusion_matrix(y_test_DS, y_test_pred_DS, model, f'Test Set with {target}', output_folder, target)\n",
    "\n",
    "    plot_feature_importance(model, X_DS, target, 30, output_folder)\n",
    "\n",
    "    metrics = pd.DataFrame({\n",
    "            'Accuracy Train': [accuracy_score(y_train_DS, y_train_pred_DS)],\n",
    "            'Accuracy Test': [accuracy_score(y_test_DS, y_test_pred_DS)],\n",
    "            'Precision': [precision_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)],\n",
    "            'Recall': [recall_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)],\n",
    "            'F1 Score': [f1_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)]\n",
    "        })\n",
    "    \n",
    "    metrics.to_csv(os.path.join(output_folder, f'{target.replace(\" \", \"_\")}_metrics.tsv'), sep='\\t')\n",
    "    print(f\"Metrics for target {target}\")\n",
    "    print(metrics)\n",
    "\n",
    "    if accuracy_score(y_test_DS, y_test_pred_DS) > 0.7:\n",
    "        print(f\"Model trained with accuracy: {accuracy_score(y_test_DS, y_test_pred_DS)}\")\n",
    "        model_file_path = os.path.join(output_folder, f'{target.replace(\" \", \"_\")}_model.joblib')\n",
    "        print(f\"Saving the model to {model_file_path}\")\n",
    "        joblib.dump(model, model_file_path)\n",
    "    else:\n",
    "        print(f\"Model trained with accuracy: {accuracy_score(y_test_DS, y_test_pred_DS)}\")\n",
    "    return y_test_DS, y_test_pred_DS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5985eb5f-d31a-44e9-8d1b-08c80ba7f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '/scratch/project_2006608/Methylation/notebooks/RF_HAMBI'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89c83e-e0b5-4b3f-a343-1e45f35fb30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data, output_folder, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ddb780-93ce-450e-af50-cb7346d956d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data, output_folder, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb2690b-62be-410c-ba1b-ce5b809fefb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data, output_folder, 'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0adfb9-1494-4a6f-9241-1ca846694f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data, output_folder, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b895c8-d143-48fb-8a68-15f53f0609f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data, output_folder, 'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08fe41f-fa7b-4bdd-860a-c8b099c357f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data, output_folder, 'p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b92a8ea-4e6d-4176-abd0-0020d4527d18",
   "metadata": {},
   "source": [
    "## Exploring different number of lines in .gff files\n",
    "### 20, 50, 100, 200, 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d5bd5b-a5cb-4174-920e-e1d450c6fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/scratch/project_2006608/Methylation/HAMBI_data/merged_data.tsv\", sep=\"\\t\", index_col=0, header=0,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1748d594-e8dc-4270-b6dd-b7e616bbf68c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61294161-7f75-4b7b-ab79-9e103f914c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete all rows with < 50 / < 100 / < 200 / < 500 mod counts\n",
    "## Bring the contig lengths from Puhti:\n",
    "file_path = '/scratch/project_2006608/Methylation/HAMBI_data/metagenomic_assembly/contigs_mod_counts.tsv'\n",
    "\n",
    "df_mod_counts = pd.read_csv(file_path, sep='\\t', index_col=0, header=0, low_memory=False)\n",
    "print(df_mod_counts.shape[0])\n",
    "df_mod_counts.head()\n",
    "\n",
    "## Append to merged_data.tsv\n",
    "data_ext = data.copy()\n",
    "data_mod_counts = pd.concat([data_ext, df_mod_counts], axis=1)\n",
    "data_mod_counts.head()\n",
    "\n",
    "#data_mod_counts = data_mod_counts.loc[data_mod_counts['mod_count'] >= 50]\n",
    "#data_mod_counts = data_mod_counts.loc[data_mod_counts['mod_count'] >= 100]\n",
    "#data_mod_counts = data_mod_counts.loc[data_mod_counts['mod_count'] >= 200]\n",
    "data_mod_counts = data_mod_counts.loc[data_mod_counts['mod_count'] >= 500]\n",
    "\n",
    "print(data_mod_counts.shape[0])\n",
    "\n",
    "#len(data_mod_counts['Domain to species'].value_counts(dropna=True))\n",
    "len(data_mod_counts['Domain to species'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a051bb-cf68-4111-a712-0fe1d8980999",
   "metadata": {},
   "source": [
    "## Random forest classifier \n",
    "#### Filtered by mod counts\n",
    "##### > 50\n",
    "##### > 100\n",
    "##### > 200\n",
    "##### > 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a4023-9eb0-4d4d-923c-b7333ddffc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data_mod_counts: pd.DataFrame) -> pd.DataFrame:\n",
    "    classes_before = set(data_mod_counts['s'].unique())\n",
    "    print(f\"before filtering number of classes {len(data_mod_counts['s'].value_counts())}\")   \n",
    "    data_mod_counts_filtered = data_mod_counts.dropna(subset=['All'], axis=0)\n",
    "    data_mod_counts_filtered = data_mod_counts_filtered[(data_mod_counts_filtered['All'] != '') & (data_mod_counts_filtered['All'] != 'Bacteria')]\n",
    "    data_mod_counts_filtered = data_mod_counts_filtered[(data_mod_counts_filtered.iloc[:, :492] != 0).any(axis=1)]\n",
    "    print(f\"after filtering number of classes {len(data_mod_counts_filtered['s'].value_counts())}\")\n",
    "    classes_after = set(data_mod_counts_filtered['s'].unique())\n",
    "    dropped_classes = classes_before - classes_after\n",
    "    if dropped_classes:\n",
    "        print(f\"Dropped classes: {dropped_classes}\")\n",
    "    else:\n",
    "        print(\"No classes were dropped.\")\n",
    "    return data_mod_counts_filtered\n",
    "\n",
    "def filter_out_n(data: pd.DataFrame, column_name: str, n: int) -> pd.DataFrame:\n",
    "    \"\"\"Filter out the contigs that have less than n samples in the given column.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): Data frame with the data.\n",
    "    - column_name (str): Column name to filter out.\n",
    "    - n (int): Minimum number of samples.\n",
    "    \"\"\"\n",
    "    print(f\"before filtering number of classes {len(data_mod_counts[column_name].value_counts())}\")\n",
    "    counts = data_mod_counts[column_name].value_counts()\n",
    "    classes = counts[counts > n].index\n",
    "    filtered_data_mod_counts = data_mod_counts[data_mod_counts[column_name].isin(classes)]\n",
    "    filtered_data_mod_counts = filtered_data_mod_counts.dropna(subset=[column_name], axis=0)\n",
    "    print(f\"after filtering number of classes {len(filtered_data_mod_counts[column_name].value_counts())}\")\n",
    "\n",
    "    return filtered_data_mod_counts\n",
    "\n",
    "def plot_confusion_matrix(y_true: pd.Series, y_pred: pd.Series, model: RandomForestClassifier, title: str, output_dir: str, target: str):\n",
    "    \"\"\"Plot the confusion matrix for the given true and predicted values.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true (pd.Series): True labels.\n",
    "    - y_pred (pd.Series): Predicted labels.\n",
    "    - model (RandomForestClassifier): Trained model.\n",
    "    - title (str): Title of the plot.\n",
    "    - output_dir (str): Path to the output directory where the plot will be saved.\n",
    "    - target (str): Target column.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Replace zeros with np.nan to mask them\n",
    "    cm_nan = cm.astype(float)\n",
    "    cm_nan[cm_nan == 0] = np.nan\n",
    "\n",
    "    # Copy the colormap and set the color for NaNs (bad values)\n",
    "    base_cmap = copy(plt.get_cmap(\"YlGnBu\"))\n",
    "    base_cmap.set_bad(color=\"#FFFFF7\")  # lighter color for zero\n",
    "\n",
    "    # Prepare annotation: show numbers except for NaNs (which become empty strings)\n",
    "    annot = np.where(np.isnan(cm_nan), \"\", cm_nan.astype(int).astype(str))\n",
    "    \n",
    "    # For Species\n",
    "    #clean_labels = [label.replace(\"_\", \" \") for label in model.classes_]\n",
    "    \n",
    "    plt.figure(figsize=(50, 50))\n",
    "\n",
    "    sns.heatmap(cm_nan, cmap=base_cmap, annot=annot, fmt='',\n",
    "    # For species\n",
    "        #xticklabels=clean_labels, yticklabels=clean_labels,\n",
    "        xticklabels=model.classes_, yticklabels=model.classes_,\n",
    "                cbar=True, annot_kws={\"size\": 60}, cbar_kws={'label': '', 'shrink': 0.8, 'aspect': 30, 'orientation': 'vertical'})\n",
    "\n",
    "    plt.xticks(rotation = 40, ha='right', fontsize=60, fontstyle='italic')\n",
    "    plt.yticks(rotation=0, fontsize=60, fontstyle='italic')\n",
    "\n",
    "    # Edit legend labels\n",
    "    ax = plt.gca()\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=60)\n",
    "\n",
    "    plt.title(f'{title} - Accuracy: {accuracy_score(y_true, y_pred):.2f}', fontsize=110)\n",
    "    # For species\n",
    "    #xticklabels=clean_labels,\n",
    "    #yticklabels=clean_labels,\n",
    "    xticklabels=model.classes_,\n",
    "    yticklabels=model.classes_,\n",
    "    plt.xlabel('Predicted labels', fontsize=80, fontweight='bold')\n",
    "    plt.ylabel('True labels', fontsize=80, fontweight='bold')\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    title = title.replace(' ', '_')\n",
    "    plt.savefig(os.path.join(output_dir, f'{title}.png'))\n",
    "    plt.savefig(os.path.join(output_dir, f'{title}.svg'))\n",
    "\n",
    "    # Edit when you have chosen the number of features\n",
    "    plt.savefig(os.path.join(output_folder, f'{target}_confusion_mat.png'), bbox_inches='tight')\n",
    "    plt.savefig(os.path.join(output_folder, f'{target}_confusion_mat.svg'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "def plot_train_test_distribution(y_train: pd.Series, y_test: pd.Series, output_dir: str, target: str):\n",
    "    \"\"\"Plot the distribution of the train and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_train (pd.Series): True labels of the train set.\n",
    "    - y_test (pd.Series): True labels of the test set.\n",
    "    - output_dir (str): Path to the output directory.\n",
    "    \"\"\"\n",
    "    print(\"Plotting the distribution\")\n",
    "    train_species_counts = y_train.value_counts()\n",
    "    test_species_counts = y_test.value_counts()\n",
    "    \n",
    "    print(\"Number of samples in each species in the train set:\")\n",
    "    print(train_species_counts)\n",
    "    print(\"\\nNumber of samples in each species in the test set:\")\n",
    "    print(test_species_counts)\n",
    "    num_classes = len(set(y_train.unique()).union(set(y_test.unique())))\n",
    "    \n",
    "    width = max(12, num_classes * 0.6)\n",
    "    height = max(8, num_classes * 0.8)\n",
    "    \n",
    "    plt.figure(figsize=(width, height))\n",
    "    \n",
    "    categories = pd.concat([y_train, y_test]).value_counts().index\n",
    "    train_counts = y_train.value_counts().reindex(categories, fill_value=0)\n",
    "    test_counts = y_test.value_counts().reindex(categories, fill_value=0)\n",
    "    \n",
    "    indices = range(len(categories))\n",
    "    bar_width = 0.4 \n",
    "\n",
    "    # For species\n",
    "    #labels = [\"Citrobacter_B_koseri\", \"Pseudomonas_E_putida\", \"Bordetella_avium\", \"Microvirga_lotononidis\",\n",
    "    #          \"Paracoccus_denitrificans\", \"Comamonas_testosteroni_C\", \"Pseudomonas_E_chlororaphis\", \"Morganella_morganii\",\n",
    "    #          \"Cupriavidus_oxalaticus\", \"Sphingobium_yanoikuyae\", \"Aeromonas_caviae\"]   \n",
    "    #clean_labels = [label.replace(\"_\", \" \") for label in labels]\n",
    "    \n",
    "    plt.bar([i - bar_width / 2 for i in indices], train_counts, width=bar_width, color='blue', alpha=0.5, label='Train')\n",
    "    plt.bar([i + bar_width / 2 for i in indices], test_counts, width=bar_width, color='red', alpha=0.5, label='Test')\n",
    "\n",
    "    # For species\n",
    "    #plt.xticks(indices, clean_labels, fontsize=16, fontstyle='italic', rotation = 40, ha='right')\n",
    "    \n",
    "    # Other than species:\n",
    "    plt.xticks(indices, categories, fontsize=16, fontstyle='italic', rotation = 40, ha='right')\n",
    "    \n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.title(f'Distribution of train and test set data', fontsize=30)\n",
    "    plt.subplots_adjust(bottom=0.3)\n",
    "    \n",
    "    target = target.replace(' ', '_')\n",
    "    plt.savefig(os.path.join(output_dir, f'{target}_train_test_distribution.png'), bbox_inches='tight')\n",
    "    plt.savefig(os.path.join(output_dir, f'{target}_train_test_distribution.svg'))\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_importance(model: RandomForestClassifier, X: pd.DataFrame, target:str, top_n: int = 30, output_dir: str = None):\n",
    "    \"\"\"Plot the feature importance of the model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model (RandomForestClassifier): Trained model.\n",
    "    - X (pd.DataFrame): Data frame with the features.\n",
    "    - target (str): Target column.\n",
    "    - top_n (int): Number of top features to plot.\n",
    "    - output_dir (str): Path to the output directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    methylation_colors = {'m6A': '#BF5137',\n",
    "                          'm4C': '#365E46',\n",
    "                          'modified_base': '#ABC7C9',\n",
    "                          'other': 'gray'}\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    top_indices = indices[:top_n]\n",
    "    top_features = X.columns[top_indices]\n",
    "\n",
    "    def get_color(feature_name):\n",
    "        if 'm6A' in feature_name:\n",
    "            return methylation_colors['m6A']\n",
    "        elif 'm4C' in feature_name:\n",
    "            return methylation_colors['m4C']\n",
    "        elif 'modified_base' in feature_name:\n",
    "            return methylation_colors['modified_base']\n",
    "        else:\n",
    "            return methylation_colors['other']\n",
    "\n",
    "    bar_colors = [get_color(feature) for feature in top_features]\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.bar(range(top_n), importances[top_indices], align='center', color=bar_colors)\n",
    "    plt.xticks(range(top_n), X.columns[top_indices], rotation=45, ha='right', fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.title(f\"Top {top_n} features with species\", fontsize=50)\n",
    "    plt.xlim(-0.5, len(top_indices) - 0.5)\n",
    "    plt.tight_layout()\n",
    "    output_name = f'{target.replace(\" \", \"_\")}_feature_importance_colors.png'\n",
    "    plt.savefig(os.path.join(output_dir, f'{target}_feature_importance_colors.png'))\n",
    "    plt.savefig(os.path.join(output_dir, f'{target}_feature_importance_colors.svg'))\n",
    "    plt.close()\n",
    "\n",
    "def train_test_model(df: pd.DataFrame, output_folder: str, target: str):\n",
    "    \"\"\"Train and test the random forest classifier.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Data frame with the data.\n",
    "    - output_folder (str): Path to the output directory to save the results for the model plots\n",
    "    - target (str): Target column.\n",
    "    \"\"\"\n",
    "    print(f\"Training the model with target: {target}\")\n",
    "    filtered_data_mod_counts = clean_data(df)\n",
    "    filtered_data_mod_counts = filter_out_n(filtered_data_mod_counts, target, 10)\n",
    "    \n",
    "    X_DS = filtered_data_mod_counts.iloc[:, :492] \n",
    "    y_DS = filtered_data_mod_counts[target]\n",
    "\n",
    "    X_train_DS, X_test_DS, y_train_DS, y_test_DS = train_test_split(X_DS, y_DS, test_size=0.2, random_state=seed, stratify=y_DS)\n",
    "    plot_train_test_distribution(y_train_DS, y_test_DS, output_folder, target)\n",
    "    model = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "    model.fit(X_train_DS, y_train_DS)\n",
    "\n",
    "    y_train_pred_DS = model.predict(X_train_DS)\n",
    "    y_test_pred_DS = model.predict(X_test_DS)\n",
    "\n",
    "    # For species\n",
    "    #labels = [\"Citrobacter_B_koseri\", \"Pseudomonas_E_putida\", \"Bordetella_avium\", \"Microvirga_lotononidis\",\n",
    "    #          \"Paracoccus_denitrificans\", \"Comamonas_testosteroni_C\", \"Pseudomonas_E_chlororaphis\", \"Morganella_morganii\",\n",
    "    #          \"Cupriavidus_oxalaticus\", \"Sphingobium_yanoikuyae\", \"Aeromonas_caviae\"]\n",
    "    #clean_labels = [label.replace(\"_\", \" \") for label in labels]\n",
    "\n",
    "    plot_confusion_matrix(y_train_DS, y_train_pred_DS, model, f'Train Set with {target}', output_folder, target)\n",
    "    plot_confusion_matrix(y_test_DS, y_test_pred_DS, model, f'Test Set with {target}', output_folder, target)\n",
    "\n",
    "    plot_feature_importance(model, X_DS, target, 30, output_folder)\n",
    "\n",
    "    metrics = pd.DataFrame({\n",
    "            'Accuracy Train': [accuracy_score(y_train_DS, y_train_pred_DS)],\n",
    "            'Accuracy Test': [accuracy_score(y_test_DS, y_test_pred_DS)],\n",
    "            'Precision': [precision_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)],\n",
    "            'Recall': [recall_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)],\n",
    "            'F1 Score': [f1_score(y_test_DS, y_test_pred_DS, average='weighted', zero_division=0)]\n",
    "        })\n",
    "    \n",
    "    metrics.to_csv(os.path.join(output_folder, f'{target.replace(\" \", \"_\")}_metrics.tsv'), sep='\\t')\n",
    "    print(f\"Metrics for target {target}\")\n",
    "    print(metrics)\n",
    "\n",
    "    if accuracy_score(y_test_DS, y_test_pred_DS) > 0.7:\n",
    "        print(f\"Model trained with accuracy: {accuracy_score(y_test_DS, y_test_pred_DS)}\")\n",
    "        model_file_path = os.path.join(output_folder, f'{target.replace(\" \", \"_\")}_model.joblib')\n",
    "        print(f\"Saving the model to {model_file_path}\")\n",
    "        joblib.dump(model, model_file_path)\n",
    "    else:\n",
    "        print(f\"Model trained with accuracy: {accuracy_score(y_test_DS, y_test_pred_DS)}\")\n",
    "    return y_test_DS, y_test_pred_DS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883968c8-ef76-43f0-9575-f804a0ad9bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_folder = '/scratch/project_2006608/Methylation/notebooks/RF_HAMBI_above50'\n",
    "#output_folder = '/scratch/project_2006608/Methylation/notebooks/RF_HAMBI_above100'\n",
    "#output_folder = '/scratch/project_2006608/Methylation/notebooks/RF_HAMBI_above200'\n",
    "output_folder = '/scratch/project_2006608/Methylation/notebooks/RF_HAMBI_above500'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcfc3c1-eba1-4b42-bd66-859d8aadc865",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DS, y_test_pred_DS = train_test_model(data_mod_counts, output_folder, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad49b15-a54e-49e0-9a60-0dc126424aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(y_test_pred_DS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a5f301-1f85-4778-9cfe-6c11799b0c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data_mod_counts, output_folder, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f17e3-e8a2-4078-8cb9-8510a3b02874",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data_mod_counts, output_folder, 'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e40ec-3762-4044-917b-45a10123504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data_mod_counts, output_folder, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b011c594-7a81-4888-9cc3-6bb60591a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data_mod_counts, output_folder, 'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d989f125-e336-4449-9d4b-1aca83f642ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_model(data_mod_counts, output_folder, 'p')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
